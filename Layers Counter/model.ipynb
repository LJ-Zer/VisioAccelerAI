{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: [  1 320 320   3]\n",
      "Input type: <class 'numpy.float32'>\n",
      "Output shape: [ 1 10]\n",
      "Output type: <class 'numpy.float32'>\n",
      "Layer 0: serving_default_input:0 - [  1 320 320   3]\n",
      "Layer 1: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/Reshape/shape - [3]\n",
      "Layer 2: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_1/shape - [3]\n",
      "Layer 3: anchors - [12804     4]\n",
      "Layer 4: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape/shape - [4]\n",
      "Layer 5: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape_1/shape - [4]\n",
      "Layer 6: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling_1/Reshape/shape - [4]\n",
      "Layer 7: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling_1/Reshape_1/shape - [4]\n",
      "Layer 8: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/bn_Conv1/FusedBatchNormV3 - [32]\n",
      "Layer 9: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise_BN/FusedBatchNormV3 - [32]\n",
      "Layer 10: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_expand_BN/FusedBatchNormV3 - [96]\n",
      "Layer 11: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise_BN/FusedBatchNormV3 - [96]\n",
      "Layer 12: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_expand_BN/FusedBatchNormV3 - [144]\n",
      "Layer 13: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_depthwise_BN/FusedBatchNormV3 - [144]\n",
      "Layer 14: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_expand_BN/FusedBatchNormV3 - [144]\n",
      "Layer 15: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_BN/FusedBatchNormV3 - [144]\n",
      "Layer 16: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_expand_BN/FusedBatchNormV3 - [192]\n",
      "Layer 17: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_depthwise_BN/FusedBatchNormV3 - [192]\n",
      "Layer 18: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_expand_BN/FusedBatchNormV3 - [192]\n",
      "Layer 19: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_depthwise_BN/FusedBatchNormV3 - [192]\n",
      "Layer 20: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_expand_BN/FusedBatchNormV3 - [192]\n",
      "Layer 21: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3 - [192]\n",
      "Layer 22: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_expand_BN/FusedBatchNormV3 - [384]\n",
      "Layer 23: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_depthwise_BN/FusedBatchNormV3 - [384]\n",
      "Layer 24: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_expand_BN/FusedBatchNormV3 - [384]\n",
      "Layer 25: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_depthwise_BN/FusedBatchNormV3 - [384]\n",
      "Layer 26: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_expand_BN/FusedBatchNormV3 - [384]\n",
      "Layer 27: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_depthwise_BN/FusedBatchNormV3 - [384]\n",
      "Layer 28: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_expand_BN/FusedBatchNormV3 - [384]\n",
      "Layer 29: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3 - [384]\n",
      "Layer 30: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_expand_BN/FusedBatchNormV3 - [576]\n",
      "Layer 31: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_depthwise_BN/FusedBatchNormV3 - [576]\n",
      "Layer 32: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_expand_BN/FusedBatchNormV3 - [576]\n",
      "Layer 33: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_depthwise_BN/FusedBatchNormV3 - [576]\n",
      "Layer 34: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_expand_BN/FusedBatchNormV3 - [576]\n",
      "Layer 35: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3 - [576]\n",
      "Layer 36: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_expand_BN/FusedBatchNormV3 - [960]\n",
      "Layer 37: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_depthwise_BN/FusedBatchNormV3 - [960]\n",
      "Layer 38: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_expand_BN/FusedBatchNormV3 - [960]\n",
      "Layer 39: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_depthwise_BN/FusedBatchNormV3 - [960]\n",
      "Layer 40: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_expand_BN/FusedBatchNormV3 - [960]\n",
      "Layer 41: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3 - [960]\n",
      "Layer 42: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv_1_bn/FusedBatchNormV3 - [1280]\n",
      "Layer 43: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/FusedBatchNormV3 - [128]\n",
      "Layer 44: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/FusedBatchNormV3 - [128]\n",
      "Layer 45: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20_batchnorm/FusedBatchNormV3 - [128]\n",
      "Layer 46: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21_batchnorm/FusedBatchNormV3 - [128]\n",
      "Layer 47: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_0/FusedBatchNormV3 - [128]\n",
      "Layer 48: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_1/FusedBatchNormV3 - [128]\n",
      "Layer 49: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_2/FusedBatchNormV3 - [128]\n",
      "Layer 50: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_3/FusedBatchNormV3 - [128]\n",
      "Layer 51: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_4/FusedBatchNormV3 - [128]\n",
      "Layer 52: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_0/FusedBatchNormV3 - [128]\n",
      "Layer 53: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_1/FusedBatchNormV3 - [128]\n",
      "Layer 54: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_2/FusedBatchNormV3 - [128]\n",
      "Layer 55: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_3/FusedBatchNormV3 - [128]\n",
      "Layer 56: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_4/FusedBatchNormV3 - [128]\n",
      "Layer 57: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_0/FusedBatchNormV3 - [128]\n",
      "Layer 58: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_1/FusedBatchNormV3 - [128]\n",
      "Layer 59: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_2/FusedBatchNormV3 - [128]\n",
      "Layer 60: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_3/FusedBatchNormV3 - [128]\n",
      "Layer 61: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_4/FusedBatchNormV3 - [128]\n",
      "Layer 62: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_0/FusedBatchNormV3 - [128]\n",
      "Layer 63: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_1/FusedBatchNormV3 - [128]\n",
      "Layer 64: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_2/FusedBatchNormV3 - [128]\n",
      "Layer 65: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_3/FusedBatchNormV3 - [128]\n",
      "Layer 66: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_4/FusedBatchNormV3 - [128]\n",
      "Layer 67: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D - [32  3  3  3]\n",
      "Layer 68: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_project/Conv2D - [16  1  1 32]\n",
      "Layer 69: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_expand/Conv2D - [96  1  1 16]\n",
      "Layer 70: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_project/Conv2D - [24  1  1 96]\n",
      "Layer 71: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_expand/Conv2D - [144   1   1  24]\n",
      "Layer 72: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_project/Conv2D - [ 24   1   1 144]\n",
      "Layer 73: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_expand/Conv2D - [144   1   1  24]\n",
      "Layer 74: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_project/Conv2D - [ 32   1   1 144]\n",
      "Layer 75: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_expand/Conv2D - [192   1   1  32]\n",
      "Layer 76: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_project/Conv2D - [ 32   1   1 192]\n",
      "Layer 77: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_expand/Conv2D - [192   1   1  32]\n",
      "Layer 78: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D - [ 32   1   1 192]\n",
      "Layer 79: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise - [128]\n",
      "Layer 80: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/Conv2D - [128   1   1  32]\n",
      "Layer 81: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_expand/Conv2D - [192   1   1  32]\n",
      "Layer 82: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_project/Conv2D - [ 64   1   1 192]\n",
      "Layer 83: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_expand/Conv2D - [384   1   1  64]\n",
      "Layer 84: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_project/Conv2D - [ 64   1   1 384]\n",
      "Layer 85: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_expand/Conv2D - [384   1   1  64]\n",
      "Layer 86: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_project/Conv2D - [ 64   1   1 384]\n",
      "Layer 87: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_expand/Conv2D - [384   1   1  64]\n",
      "Layer 88: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D - [ 64   1   1 384]\n",
      "Layer 89: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_expand/Conv2D - [384   1   1  64]\n",
      "Layer 90: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_project/Conv2D - [ 96   1   1 384]\n",
      "Layer 91: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_expand/Conv2D - [576   1   1  96]\n",
      "Layer 92: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_project/Conv2D - [ 96   1   1 576]\n",
      "Layer 93: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_expand/Conv2D - [576   1   1  96]\n",
      "Layer 94: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D - [ 96   1   1 576]\n",
      "Layer 95: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/Conv2D - [128   1   1  96]\n",
      "Layer 96: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_expand/Conv2D - [576   1   1  96]\n",
      "Layer 97: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_project/Conv2D - [160   1   1 576]\n",
      "Layer 98: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_expand/Conv2D - [960   1   1 160]\n",
      "Layer 99: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_project/Conv2D - [160   1   1 960]\n",
      "Layer 100: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_expand/Conv2D - [960   1   1 160]\n",
      "Layer 101: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D - [160   1   1 960]\n",
      "Layer 102: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_expand/Conv2D - [960   1   1 160]\n",
      "Layer 103: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_project/Conv2D - [320   1   1 960]\n",
      "Layer 104: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv_1/Conv2D - [1280    1    1  320]\n",
      "Layer 105: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/Conv2D - [ 128    1    1 1280]\n",
      "Layer 106: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_depthwise_conv/separable_conv2d/depthwise - [  1   3   3 128]\n",
      "Layer 107: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_depthwise_conv/separable_conv2d - [128   1   1 128]\n",
      "Layer 108: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_depthwise_conv/separable_conv2d/depthwise - [  1   3   3 128]\n",
      "Layer 109: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_depthwise_conv/separable_conv2d - [128   1   1 128]\n",
      "Layer 110: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20_depthwise_conv/separable_conv2d/depthwise - [  1   3   3 128]\n",
      "Layer 111: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20_depthwise_conv/separable_conv2d - [128   1   1 128]\n",
      "Layer 112: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21_depthwise_conv/separable_conv2d/depthwise - [  1   3   3 128]\n",
      "Layer 113: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21_depthwise_conv/separable_conv2d - [128   1   1 128]\n",
      "Layer 114: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_4/depthwise - [  1   3   3 128]\n",
      "Layer 115: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d - [128   1   1 128]\n",
      "Layer 116: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_1 - [128   1   1 128]\n",
      "Layer 117: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_2 - [128   1   1 128]\n",
      "Layer 118: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_3 - [128   1   1 128]\n",
      "Layer 119: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_4 - [128   1   1 128]\n",
      "Layer 120: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_4/depthwise - [  1   3   3 128]\n",
      "Layer 121: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d - [128   1   1 128]\n",
      "Layer 122: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_1 - [128   1   1 128]\n",
      "Layer 123: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_2 - [128   1   1 128]\n",
      "Layer 124: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_3 - [128   1   1 128]\n",
      "Layer 125: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_4 - [128   1   1 128]\n",
      "Layer 126: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_4/depthwise - [  1   3   3 128]\n",
      "Layer 127: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d - [128   1   1 128]\n",
      "Layer 128: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_1 - [128   1   1 128]\n",
      "Layer 129: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_2 - [128   1   1 128]\n",
      "Layer 130: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_3 - [128   1   1 128]\n",
      "Layer 131: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_4 - [128   1   1 128]\n",
      "Layer 132: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_4/depthwise - [  1   3   3 128]\n",
      "Layer 133: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d - [128   1   1 128]\n",
      "Layer 134: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_1 - [128   1   1 128]\n",
      "Layer 135: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_2 - [128   1   1 128]\n",
      "Layer 136: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_3 - [128   1   1 128]\n",
      "Layer 137: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_4 - [128   1   1 128]\n",
      "Layer 138: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4/depthwise - [  1   3   3 128]\n",
      "Layer 139: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4 - [ 24   1   1 128]\n",
      "Layer 140: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise1 - [  1   3   3 128]\n",
      "Layer 141: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4 - [ 30   1   1 128]\n",
      "Layer 142: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D - [ 1  3  3 32]\n",
      "Layer 143: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_project/Conv2D - [16]\n",
      "Layer 144: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D - [ 1  3  3 96]\n",
      "Layer 145: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_project_BN/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_project/Conv2D - [24]\n",
      "Layer 146: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise/depthwise - [  1   3   3 144]\n",
      "Layer 147: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_project_BN/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_project/Conv2D - [24]\n",
      "Layer 148: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise/depthwise - [  1   3   3 144]\n",
      "Layer 149: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_project/Conv2D - [32]\n",
      "Layer 150: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise - [  1   3   3 192]\n",
      "Layer 151: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_project/Conv2D - [32]\n",
      "Layer 152: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise - [  1   3   3 192]\n",
      "Layer 153: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D - [32]\n",
      "Layer 154: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/BiasAdd/ReadVariableOp - [128]\n",
      "Layer 155: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise - [  1   3   3 192]\n",
      "Layer 156: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_project/Conv2D - [64]\n",
      "Layer 157: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise - [  1   3   3 384]\n",
      "Layer 158: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_project/Conv2D - [64]\n",
      "Layer 159: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise - [  1   3   3 384]\n",
      "Layer 160: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_project/Conv2D - [64]\n",
      "Layer 161: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise - [  1   3   3 384]\n",
      "Layer 162: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D - [64]\n",
      "Layer 163: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise - [  1   3   3 384]\n",
      "Layer 164: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_project/Conv2D - [96]\n",
      "Layer 165: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise - [  1   3   3 576]\n",
      "Layer 166: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_project/Conv2D - [96]\n",
      "Layer 167: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise - [  1   3   3 576]\n",
      "Layer 168: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D - [96]\n",
      "Layer 169: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd/ReadVariableOp - [128]\n",
      "Layer 170: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise - [  1   3   3 576]\n",
      "Layer 171: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_project/Conv2D - [160]\n",
      "Layer 172: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise - [  1   3   3 960]\n",
      "Layer 173: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_project/Conv2D - [160]\n",
      "Layer 174: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise - [  1   3   3 960]\n",
      "Layer 175: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D - [160]\n",
      "Layer 176: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise - [  1   3   3 960]\n",
      "Layer 177: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_project/Conv2D - [320]\n",
      "Layer 178: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/BiasAdd/ReadVariableOp - [128]\n",
      "Layer 179: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd/ReadVariableOp - [24]\n",
      "Layer 180: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd/ReadVariableOp - [30]\n",
      "Layer 181: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/bn_Conv1/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv1/Conv2D - [  1 160 160  32]\n",
      "Layer 182: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D - [  1 160 160  32]\n",
      "Layer 183: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/expanded_conv_project/Conv2D1 - [  1 160 160  16]\n",
      "Layer 184: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_expand/Conv2D - [  1 160 160  96]\n",
      "Layer 185: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D - [ 1 80 80 96]\n",
      "Layer 186: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_project_BN/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_1_project/Conv2D1 - [ 1 80 80 24]\n",
      "Layer 187: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_expand/Conv2D - [  1  80  80 144]\n",
      "Layer 188: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_depthwise/depthwise - [  1  80  80 144]\n",
      "Layer 189: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_project_BN/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_project/Conv2D1 - [ 1 80 80 24]\n",
      "Layer 190: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_2_add/add - [ 1 80 80 24]\n",
      "Layer 191: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_expand/Conv2D - [  1  80  80 144]\n",
      "Layer 192: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_depthwise/depthwise - [  1  40  40 144]\n",
      "Layer 193: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_3_project/Conv2D1 - [ 1 40 40 32]\n",
      "Layer 194: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_expand/Conv2D - [  1  40  40 192]\n",
      "Layer 195: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_depthwise/depthwise - [  1  40  40 192]\n",
      "Layer 196: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_project/Conv2D1 - [ 1 40 40 32]\n",
      "Layer 197: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_4_add/add - [ 1 40 40 32]\n",
      "Layer 198: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_expand/Conv2D - [  1  40  40 192]\n",
      "Layer 199: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_depthwise/depthwise - [  1  40  40 192]\n",
      "Layer 200: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_project/Conv2D1 - [ 1 40 40 32]\n",
      "Layer 201: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_5_add/add - [ 1 40 40 32]\n",
      "Layer 202: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_1/BiasAdd/ReadVariableOp1 - [  1  40  40 128]\n",
      "Layer 203: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_expand/Conv2D - [  1  40  40 192]\n",
      "Layer 204: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_depthwise/depthwise - [  1  20  20 192]\n",
      "Layer 205: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_6_project/Conv2D1 - [ 1 20 20 64]\n",
      "Layer 206: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_expand/Conv2D - [  1  20  20 384]\n",
      "Layer 207: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_depthwise/depthwise - [  1  20  20 384]\n",
      "Layer 208: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_project/Conv2D1 - [ 1 20 20 64]\n",
      "Layer 209: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_7_add/add - [ 1 20 20 64]\n",
      "Layer 210: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_expand/Conv2D - [  1  20  20 384]\n",
      "Layer 211: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_depthwise/depthwise - [  1  20  20 384]\n",
      "Layer 212: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_project/Conv2D1 - [ 1 20 20 64]\n",
      "Layer 213: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_8_add/add - [ 1 20 20 64]\n",
      "Layer 214: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_expand/Conv2D - [  1  20  20 384]\n",
      "Layer 215: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_depthwise/depthwise - [  1  20  20 384]\n",
      "Layer 216: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_project/Conv2D1 - [ 1 20 20 64]\n",
      "Layer 217: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_9_add/add - [ 1 20 20 64]\n",
      "Layer 218: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_expand/Conv2D - [  1  20  20 384]\n",
      "Layer 219: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_depthwise/depthwise - [  1  20  20 384]\n",
      "Layer 220: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_10_project/Conv2D1 - [ 1 20 20 96]\n",
      "Layer 221: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_expand/Conv2D - [  1  20  20 576]\n",
      "Layer 222: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_depthwise/depthwise - [  1  20  20 576]\n",
      "Layer 223: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_project/Conv2D1 - [ 1 20 20 96]\n",
      "Layer 224: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_11_add/add - [ 1 20 20 96]\n",
      "Layer 225: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_expand/Conv2D - [  1  20  20 576]\n",
      "Layer 226: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_depthwise/depthwise - [  1  20  20 576]\n",
      "Layer 227: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_project/Conv2D1 - [ 1 20 20 96]\n",
      "Layer 228: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_12_add/add - [ 1 20 20 96]\n",
      "Layer 229: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_2/BiasAdd/ReadVariableOp1 - [  1  20  20 128]\n",
      "Layer 230: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_expand/Conv2D - [  1  20  20 576]\n",
      "Layer 231: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_depthwise/depthwise - [  1  10  10 576]\n",
      "Layer 232: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_13_project/Conv2D1 - [  1  10  10 160]\n",
      "Layer 233: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_expand/Conv2D - [  1  10  10 960]\n",
      "Layer 234: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_depthwise/depthwise - [  1  10  10 960]\n",
      "Layer 235: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_project/Conv2D1 - [  1  10  10 160]\n",
      "Layer 236: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_14_add/add - [  1  10  10 160]\n",
      "Layer 237: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_expand/Conv2D - [  1  10  10 960]\n",
      "Layer 238: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_depthwise/depthwise - [  1  10  10 960]\n",
      "Layer 239: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_project/Conv2D1 - [  1  10  10 160]\n",
      "Layer 240: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_15_add/add - [  1  10  10 160]\n",
      "Layer 241: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_expand_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_expand_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_expand/Conv2D - [  1  10  10 960]\n",
      "Layer 242: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_depthwise/depthwise - [  1  10  10 960]\n",
      "Layer 243: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_project_BN/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/block_16_project/Conv2D1 - [  1  10  10 320]\n",
      "Layer 244: ssd_mobile_net_v2_fpn_keras_feature_extractor/model/out_relu/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv_1_bn/FusedBatchNormV3;ssd_mobile_net_v2_fpn_keras_feature_extractor/model/Conv_1/Conv2D - [   1   10   10 1280]\n",
      "Layer 245: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/Conv2D;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/projection_3/BiasAdd/ReadVariableOp1 - [  1  10  10 128]\n",
      "Layer 246: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/w_stack - [  1  10  10   2 128]\n",
      "Layer 247: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape - [  1  10  20 128]\n",
      "Layer 248: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/h_stack - [  1  10   2  20 128]\n",
      "Layer 249: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling/Reshape_1 - [  1  20  20 128]\n",
      "Layer 250: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/add - [  1  20  20 128]\n",
      "Layer 251: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_depthwise_conv/separable_conv2d/depthwise1 - [  1  20  20 128]\n",
      "Layer 252: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_batchnorm/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_2_depthwise_conv/separable_conv2d - [  1  20  20 128]\n",
      "Layer 253: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling_1/w_stack - [  1  20  20   2 128]\n",
      "Layer 254: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling_1/Reshape - [  1  20  40 128]\n",
      "Layer 255: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling_1/h_stack - [  1  20   2  40 128]\n",
      "Layer 256: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/nearest_neighbor_upsampling/nearest_neighbor_upsampling_1/Reshape_1 - [  1  40  40 128]\n",
      "Layer 257: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/add_1 - [  1  40  40 128]\n",
      "Layer 258: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_depthwise_conv/separable_conv2d/depthwise1 - [  1  40  40 128]\n",
      "Layer 259: ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_batchnorm/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/FeatureMaps/top_down/smoothing_1_depthwise_conv/separable_conv2d - [  1  40  40 128]\n",
      "Layer 260: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20_depthwise_conv/separable_conv2d/depthwise1 - [  1   5   5 128]\n",
      "Layer 261: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20_batchnorm/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_20_depthwise_conv/separable_conv2d - [  1   5   5 128]\n",
      "Layer 262: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21_depthwise_conv/separable_conv2d/depthwise1 - [  1   3   3 128]\n",
      "Layer 263: ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21/Relu6;ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21_batchnorm/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;ssd_mobile_net_v2_fpn_keras_feature_extractor/bottom_up_Conv2d_21_depthwise_conv/separable_conv2d - [  1   3   3 128]\n",
      "Layer 264: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d/depthwise - [  1  40  40 128]\n",
      "Layer 265: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/activation_0/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_0/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d - [  1  40  40 128]\n",
      "Layer 266: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_1/depthwise - [  1  20  20 128]\n",
      "Layer 267: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/activation_1/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_1/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_1 - [  1  20  20 128]\n",
      "Layer 268: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_2/depthwise - [  1  10  10 128]\n",
      "Layer 269: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/activation_2/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_2/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_2 - [  1  10  10 128]\n",
      "Layer 270: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_3/depthwise - [  1   5   5 128]\n",
      "Layer 271: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/activation_3/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_3/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_3 - [  1   5   5 128]\n",
      "Layer 272: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_4/depthwise1 - [  1   3   3 128]\n",
      "Layer 273: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/activation_4/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/BatchNorm/feature_4/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_0/separable_conv2d_4 - [  1   3   3 128]\n",
      "Layer 274: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d/depthwise - [  1  40  40 128]\n",
      "Layer 275: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/activation_0/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_0/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d - [  1  40  40 128]\n",
      "Layer 276: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_1/depthwise - [  1  20  20 128]\n",
      "Layer 277: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/activation_1/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_1/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_1 - [  1  20  20 128]\n",
      "Layer 278: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_2/depthwise - [  1  10  10 128]\n",
      "Layer 279: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/activation_2/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_2/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_2 - [  1  10  10 128]\n",
      "Layer 280: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_3/depthwise - [  1   5   5 128]\n",
      "Layer 281: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/activation_3/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_3/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_3 - [  1   5   5 128]\n",
      "Layer 282: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_4/depthwise1 - [  1   3   3 128]\n",
      "Layer 283: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/activation_4/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/BatchNorm/feature_4/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_1/separable_conv2d_4 - [  1   3   3 128]\n",
      "Layer 284: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d/depthwise - [  1  40  40 128]\n",
      "Layer 285: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/activation_0/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_0/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d - [  1  40  40 128]\n",
      "Layer 286: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_1/depthwise - [  1  20  20 128]\n",
      "Layer 287: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/activation_1/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_1/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_1 - [  1  20  20 128]\n",
      "Layer 288: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_2/depthwise - [  1  10  10 128]\n",
      "Layer 289: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/activation_2/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_2/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_2 - [  1  10  10 128]\n",
      "Layer 290: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_3/depthwise - [  1   5   5 128]\n",
      "Layer 291: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/activation_3/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_3/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_3 - [  1   5   5 128]\n",
      "Layer 292: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_4/depthwise1 - [  1   3   3 128]\n",
      "Layer 293: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/activation_4/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/BatchNorm/feature_4/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_2/separable_conv2d_4 - [  1   3   3 128]\n",
      "Layer 294: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d/depthwise - [  1  40  40 128]\n",
      "Layer 295: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/activation_0/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_0/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d - [  1  40  40 128]\n",
      "Layer 296: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_1/depthwise - [  1  20  20 128]\n",
      "Layer 297: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/activation_1/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_1/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_1 - [  1  20  20 128]\n",
      "Layer 298: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_2/depthwise - [  1  10  10 128]\n",
      "Layer 299: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/activation_2/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_2/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_2 - [  1  10  10 128]\n",
      "Layer 300: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_3/depthwise - [  1   5   5 128]\n",
      "Layer 301: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/activation_3/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_3/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_3 - [  1   5   5 128]\n",
      "Layer 302: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_4/depthwise1 - [  1   3   3 128]\n",
      "Layer 303: WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/activation_4/Relu6;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/BatchNorm/feature_4/FusedBatchNormV3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise;WeightSharedConvolutionalBoxPredictor/PredictionTower/conv2d_3/separable_conv2d_4 - [  1   3   3 128]\n",
      "Layer 304: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d/depthwise - [  1  40  40 128]\n",
      "Layer 305: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd/ReadVariableOp - [ 1 40 40 24]\n",
      "Layer 306: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/Reshape - [   1 9600    4]\n",
      "Layer 307: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_1/depthwise - [  1  20  20 128]\n",
      "Layer 308: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd_1;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_1;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd/ReadVariableOp - [ 1 20 20 24]\n",
      "Layer 309: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/Reshape_1 - [   1 2400    4]\n",
      "Layer 310: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_2/depthwise - [  1  10  10 128]\n",
      "Layer 311: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd_2;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_2;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd/ReadVariableOp - [ 1 10 10 24]\n",
      "Layer 312: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/Reshape_2 - [  1 600   4]\n",
      "Layer 313: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_3/depthwise - [  1   5   5 128]\n",
      "Layer 314: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd_3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd/ReadVariableOp - [ 1  5  5 24]\n",
      "Layer 315: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/Reshape_3 - [  1 150   4]\n",
      "Layer 316: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4/depthwise1 - [  1   3   3 128]\n",
      "Layer 317: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/BoxPredictor/BiasAdd/ReadVariableOp1 - [ 1  3  3 24]\n",
      "Layer 318: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalBoxHead/Reshape_4 - [ 1 54  4]\n",
      "Layer 319: concat - [    1 12804     4]\n",
      "Layer 320: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d/depthwise - [  1  40  40 128]\n",
      "Layer 321: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd/ReadVariableOp - [ 1 40 40 30]\n",
      "Layer 322: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_1;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape - [   1 9600    5]\n",
      "Layer 323: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_1/depthwise - [  1  20  20 128]\n",
      "Layer 324: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd_1;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_1;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd/ReadVariableOp - [ 1 20 20 30]\n",
      "Layer 325: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_2 - [   1 2400    5]\n",
      "Layer 326: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_2/depthwise - [  1  10  10 128]\n",
      "Layer 327: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd_2;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_2;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd/ReadVariableOp - [ 1 10 10 30]\n",
      "Layer 328: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_5;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_4 - [  1 600   5]\n",
      "Layer 329: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_3/depthwise - [  1   5   5 128]\n",
      "Layer 330: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd_3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_3;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd/ReadVariableOp - [ 1  5  5 30]\n",
      "Layer 331: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_7;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_6 - [  1 150   5]\n",
      "Layer 332: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4/depthwise2 - [  1   3   3 128]\n",
      "Layer 333: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/separable_conv2d_4;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/ClassPredictor/BiasAdd/ReadVariableOp1 - [ 1  3  3 30]\n",
      "Layer 334: WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_9;WeightSharedConvolutionalBoxPredictor/WeightSharedConvolutionalClassHead/Reshape_8 - [ 1 54  5]\n",
      "Layer 335: concat_1 - [    1 12804     5]\n",
      "Layer 336: convert_scores - [    1 12804     5]\n",
      "Layer 337: StatefulPartitionedCall:3 - [ 1 10  4]\n",
      "Layer 338: StatefulPartitionedCall:2 - [ 1 10]\n",
      "Layer 339: StatefulPartitionedCall:1 - [ 1 10]\n",
      "Layer 340: StatefulPartitionedCall:0 - [1]\n",
      "Layer 341:  - [12804     4]\n",
      "Layer 342:  - [12804     5]\n",
      "Layer 343:  - [27 32]\n",
      "Layer 344:  - [32 16]\n",
      "Layer 345:  - [16 96]\n",
      "Layer 346:  - [96 24]\n",
      "Layer 347:  - [ 24 144]\n",
      "Layer 348:  - [144  24]\n",
      "Layer 349:  - [ 24 144]\n",
      "Layer 350:  - [144  32]\n",
      "Layer 351:  - [ 32 192]\n",
      "Layer 352:  - [192  32]\n",
      "Layer 353:  - [ 32 192]\n",
      "Layer 354:  - [192  32]\n",
      "Layer 355:  - [ 32 128]\n",
      "Layer 356:  - [ 32 192]\n",
      "Layer 357:  - [192  64]\n",
      "Layer 358:  - [ 64 384]\n",
      "Layer 359:  - [384  64]\n",
      "Layer 360:  - [ 64 384]\n",
      "Layer 361:  - [384  64]\n",
      "Layer 362:  - [ 64 384]\n",
      "Layer 363:  - [384  64]\n",
      "Layer 364:  - [ 64 384]\n",
      "Layer 365:  - [384  96]\n",
      "Layer 366:  - [ 96 576]\n",
      "Layer 367:  - [576  96]\n",
      "Layer 368:  - [ 96 576]\n",
      "Layer 369:  - [576  96]\n",
      "Layer 370:  - [ 96 128]\n",
      "Layer 371:  - [ 96 576]\n",
      "Layer 372:  - [576 160]\n",
      "Layer 373:  - [160 960]\n",
      "Layer 374:  - [960 160]\n",
      "Layer 375:  - [160 960]\n",
      "Layer 376:  - [960 160]\n",
      "Layer 377:  - [160 960]\n",
      "Layer 378:  - [960 320]\n",
      "Layer 379:  - [ 320 1280]\n",
      "Layer 380:  - [1280  128]\n",
      "Layer 381:  - [128 128]\n",
      "Layer 382:  - [128 128]\n",
      "Layer 383:  - [128 128]\n",
      "Layer 384:  - [128 128]\n",
      "Layer 385:  - [128 128]\n",
      "Layer 386:  - [128 128]\n",
      "Layer 387:  - [128 128]\n",
      "Layer 388:  - [128 128]\n",
      "Layer 389:  - [128 128]\n",
      "Layer 390:  - [128 128]\n",
      "Layer 391:  - [128 128]\n",
      "Layer 392:  - [128 128]\n",
      "Layer 393:  - [128 128]\n",
      "Layer 394:  - [128 128]\n",
      "Layer 395:  - [128 128]\n",
      "Layer 396:  - [128 128]\n",
      "Layer 397:  - [128 128]\n",
      "Layer 398:  - [128 128]\n",
      "Layer 399:  - [128 128]\n",
      "Layer 400:  - [128 128]\n",
      "Layer 401:  - [128 128]\n",
      "Layer 402:  - [128 128]\n",
      "Layer 403:  - [128 128]\n",
      "Layer 404:  - [128 128]\n",
      "Layer 405:  - [128  24]\n",
      "Layer 406:  - [128  24]\n",
      "Layer 407:  - [128  24]\n",
      "Layer 408:  - [128  24]\n",
      "Layer 409:  - [128  24]\n",
      "Layer 410:  - [128  30]\n",
      "Layer 411:  - [128  30]\n",
      "Layer 412:  - [128  30]\n",
      "Layer 413:  - [128  30]\n",
      "Layer 414:  - [128  30]\n",
      "Output: [[0.00574448 0.00540994 0.00539264 0.00525744 0.00522263 0.00513417\n",
      "  0.00504036 0.00498524 0.00495755 0.00493782]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print(\"Input shape:\", input_details[0]['shape'])\n",
    "print(\"Input type:\", input_details[0]['dtype'])\n",
    "print(\"Output shape:\", output_details[0]['shape'])\n",
    "print(\"Output type:\", output_details[0]['dtype'])\n",
    "\n",
    "\n",
    "# Get details of all layers\n",
    "for i, layer in enumerate(interpreter.get_tensor_details()):\n",
    "    print(f\"Layer {i}: {layer['name']} - {layer['shape']}\")\n",
    "\n",
    "\n",
    "\n",
    "# Generate random input data as an example\n",
    "input_data = np.random.rand(*input_details[0]['shape']).astype(np.float32)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output tensor\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "\n",
    "# Print the output\n",
    "print(\"Output:\", output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type           Output Shape           Parameters    FLOPs\n",
      "Unknown Layer Type   [  1 320 320   3]      N/A           N/A\n",
      "Convolutional Layer  [3]                    4             N/A\n",
      "Convolutional Layer  [3]                    4             N/A\n",
      "Unknown Layer Type   [12804     4]          N/A           N/A\n",
      "Unknown Layer Type   [4]                    N/A           N/A\n",
      "Unknown Layer Type   [4]                    N/A           N/A\n",
      "Unknown Layer Type   [4]                    N/A           N/A\n",
      "Unknown Layer Type   [4]                    N/A           N/A\n",
      "Convolutional Layer  [32]                   33            N/A\n",
      "Convolutional Layer  [32]                   33            N/A\n",
      "Unknown Layer Type   [96]                   N/A           N/A\n",
      "Unknown Layer Type   [96]                   N/A           N/A\n",
      "Unknown Layer Type   [144]                  N/A           N/A\n",
      "Unknown Layer Type   [144]                  N/A           N/A\n",
      "Unknown Layer Type   [144]                  N/A           N/A\n",
      "Unknown Layer Type   [144]                  N/A           N/A\n",
      "Unknown Layer Type   [192]                  N/A           N/A\n",
      "Unknown Layer Type   [192]                  N/A           N/A\n",
      "Unknown Layer Type   [192]                  N/A           N/A\n",
      "Unknown Layer Type   [192]                  N/A           N/A\n",
      "Unknown Layer Type   [192]                  N/A           N/A\n",
      "Unknown Layer Type   [192]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [384]                  N/A           N/A\n",
      "Unknown Layer Type   [576]                  N/A           N/A\n",
      "Unknown Layer Type   [576]                  N/A           N/A\n",
      "Unknown Layer Type   [576]                  N/A           N/A\n",
      "Unknown Layer Type   [576]                  N/A           N/A\n",
      "Unknown Layer Type   [576]                  N/A           N/A\n",
      "Unknown Layer Type   [576]                  N/A           N/A\n",
      "Unknown Layer Type   [960]                  N/A           N/A\n",
      "Unknown Layer Type   [960]                  N/A           N/A\n",
      "Unknown Layer Type   [960]                  N/A           N/A\n",
      "Unknown Layer Type   [960]                  N/A           N/A\n",
      "Unknown Layer Type   [960]                  N/A           N/A\n",
      "Unknown Layer Type   [960]                  N/A           N/A\n",
      "Convolutional Layer  [1280]                 1281          N/A\n",
      "Unknown Layer Type   [128]                  N/A           N/A\n",
      "Unknown Layer Type   [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [32  3  3  3]          896           7776\n",
      "Convolutional Layer  [16  1  1 32]          528           512\n",
      "Convolutional Layer  [96  1  1 16]          1632          1536\n",
      "Convolutional Layer  [24  1  1 96]          2328          2304\n",
      "Convolutional Layer  [144   1   1  24]      3600          3456\n",
      "Convolutional Layer  [ 24   1   1 144]      3480          3456\n",
      "Convolutional Layer  [144   1   1  24]      3600          3456\n",
      "Convolutional Layer  [ 32   1   1 144]      4640          4608\n",
      "Convolutional Layer  [192   1   1  32]      6336          6144\n",
      "Convolutional Layer  [ 32   1   1 192]      6176          6144\n",
      "Convolutional Layer  [192   1   1  32]      6336          6144\n",
      "Convolutional Layer  [ 32   1   1 192]      6176          6144\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [128   1   1  32]      4224          4096\n",
      "Convolutional Layer  [192   1   1  32]      6336          6144\n",
      "Convolutional Layer  [ 64   1   1 192]      12352         12288\n",
      "Convolutional Layer  [384   1   1  64]      24960         24576\n",
      "Convolutional Layer  [ 64   1   1 384]      24640         24576\n",
      "Convolutional Layer  [384   1   1  64]      24960         24576\n",
      "Convolutional Layer  [ 64   1   1 384]      24640         24576\n",
      "Convolutional Layer  [384   1   1  64]      24960         24576\n",
      "Convolutional Layer  [ 64   1   1 384]      24640         24576\n",
      "Convolutional Layer  [384   1   1  64]      24960         24576\n",
      "Convolutional Layer  [ 96   1   1 384]      36960         36864\n",
      "Convolutional Layer  [576   1   1  96]      55872         55296\n",
      "Convolutional Layer  [ 96   1   1 576]      55392         55296\n",
      "Convolutional Layer  [576   1   1  96]      55872         55296\n",
      "Convolutional Layer  [ 96   1   1 576]      55392         55296\n",
      "Convolutional Layer  [128   1   1  96]      12416         12288\n",
      "Convolutional Layer  [576   1   1  96]      55872         55296\n",
      "Convolutional Layer  [160   1   1 576]      92320         92160\n",
      "Convolutional Layer  [960   1   1 160]      154560        153600\n",
      "Convolutional Layer  [160   1   1 960]      153760        153600\n",
      "Convolutional Layer  [960   1   1 160]      154560        153600\n",
      "Convolutional Layer  [160   1   1 960]      153760        153600\n",
      "Convolutional Layer  [960   1   1 160]      154560        153600\n",
      "Convolutional Layer  [320   1   1 960]      307520        307200\n",
      "Convolutional Layer  [1280    1    1  320]  410880        409600\n",
      "Convolutional Layer  [ 128    1    1 1280]  163968        163840\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [128   1   1 128]      16512         16384\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [ 24   1   1 128]      3096          3072\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [ 30   1   1 128]      3870          3840\n",
      "Convolutional Layer  [ 1  3  3 32]          289           2592\n",
      "Convolutional Layer  [16]                   N/A           N/A\n",
      "Convolutional Layer  [ 1  3  3 96]          865           7776\n",
      "Convolutional Layer  [24]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 144]      N/A           N/A\n",
      "Convolutional Layer  [24]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 144]      N/A           N/A\n",
      "Convolutional Layer  [32]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 192]      N/A           N/A\n",
      "Convolutional Layer  [32]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 192]      N/A           N/A\n",
      "Convolutional Layer  [32]                   N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 192]      N/A           N/A\n",
      "Convolutional Layer  [64]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer  [64]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer  [64]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer  [64]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer  [96]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 576]      N/A           N/A\n",
      "Convolutional Layer  [96]                   N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 576]      N/A           N/A\n",
      "Convolutional Layer  [96]                   N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 576]      N/A           N/A\n",
      "Convolutional Layer  [160]                  N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 960]      N/A           N/A\n",
      "Convolutional Layer  [160]                  N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 960]      N/A           N/A\n",
      "Convolutional Layer  [160]                  N/A           N/A\n",
      "Unknown Layer Type   [  1   3   3 960]      N/A           N/A\n",
      "Convolutional Layer  [320]                  N/A           N/A\n",
      "Convolutional Layer  [128]                  N/A           N/A\n",
      "Convolutional Layer  [24]                   N/A           N/A\n",
      "Convolutional Layer  [30]                   N/A           N/A\n",
      "Convolutional Layer  [  1 160 160  32]      819201        20971520000\n",
      "Convolutional Layer  [  1 160 160  32]      819201        20971520000\n",
      "Convolutional Layer  [  1 160 160  16]      409601        10485760000\n",
      "Convolutional Layer  [  1 160 160  96]      2457601       62914560000\n",
      "Convolutional Layer  [ 1 80 80 96]          614401        3932160000\n",
      "Convolutional Layer  [ 1 80 80 24]          153601        983040000\n",
      "Convolutional Layer  [  1  80  80 144]      921601        5898240000\n",
      "Unknown Layer Type   [  1  80  80 144]      N/A           N/A\n",
      "Convolutional Layer  [ 1 80 80 24]          153601        983040000\n",
      "Unknown Layer Type   [ 1 80 80 24]          N/A           N/A\n",
      "Convolutional Layer  [  1  80  80 144]      921601        5898240000\n",
      "Unknown Layer Type   [  1  40  40 144]      N/A           N/A\n",
      "Convolutional Layer  [ 1 40 40 32]          51201         81920000\n",
      "Convolutional Layer  [  1  40  40 192]      307201        491520000\n",
      "Unknown Layer Type   [  1  40  40 192]      N/A           N/A\n",
      "Convolutional Layer  [ 1 40 40 32]          51201         81920000\n",
      "Unknown Layer Type   [ 1 40 40 32]          N/A           N/A\n",
      "Convolutional Layer  [  1  40  40 192]      307201        491520000\n",
      "Unknown Layer Type   [  1  40  40 192]      N/A           N/A\n",
      "Convolutional Layer  [ 1 40 40 32]          51201         81920000\n",
      "Unknown Layer Type   [ 1 40 40 32]          N/A           N/A\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  40  40 192]      307201        491520000\n",
      "Unknown Layer Type   [  1  20  20 192]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 64]          25601         10240000\n",
      "Convolutional Layer  [  1  20  20 384]      153601        61440000\n",
      "Unknown Layer Type   [  1  20  20 384]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 64]          25601         10240000\n",
      "Unknown Layer Type   [ 1 20 20 64]          N/A           N/A\n",
      "Convolutional Layer  [  1  20  20 384]      153601        61440000\n",
      "Unknown Layer Type   [  1  20  20 384]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 64]          25601         10240000\n",
      "Unknown Layer Type   [ 1 20 20 64]          N/A           N/A\n",
      "Convolutional Layer  [  1  20  20 384]      153601        61440000\n",
      "Unknown Layer Type   [  1  20  20 384]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 64]          25601         10240000\n",
      "Unknown Layer Type   [ 1 20 20 64]          N/A           N/A\n",
      "Convolutional Layer  [  1  20  20 384]      153601        61440000\n",
      "Unknown Layer Type   [  1  20  20 384]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 96]          38401         15360000\n",
      "Convolutional Layer  [  1  20  20 576]      230401        92160000\n",
      "Unknown Layer Type   [  1  20  20 576]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 96]          38401         15360000\n",
      "Unknown Layer Type   [ 1 20 20 96]          N/A           N/A\n",
      "Convolutional Layer  [  1  20  20 576]      230401        92160000\n",
      "Unknown Layer Type   [  1  20  20 576]      N/A           N/A\n",
      "Convolutional Layer  [ 1 20 20 96]          38401         15360000\n",
      "Unknown Layer Type   [ 1 20 20 96]          N/A           N/A\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  20  20 576]      230401        92160000\n",
      "Unknown Layer Type   [  1  10  10 576]      N/A           N/A\n",
      "Convolutional Layer  [  1  10  10 160]      16001         1600000\n",
      "Convolutional Layer  [  1  10  10 960]      96001         9600000\n",
      "Unknown Layer Type   [  1  10  10 960]      N/A           N/A\n",
      "Convolutional Layer  [  1  10  10 160]      16001         1600000\n",
      "Unknown Layer Type   [  1  10  10 160]      N/A           N/A\n",
      "Convolutional Layer  [  1  10  10 960]      96001         9600000\n",
      "Unknown Layer Type   [  1  10  10 960]      N/A           N/A\n",
      "Convolutional Layer  [  1  10  10 160]      16001         1600000\n",
      "Unknown Layer Type   [  1  10  10 160]      N/A           N/A\n",
      "Convolutional Layer  [  1  10  10 960]      96001         9600000\n",
      "Unknown Layer Type   [  1  10  10 960]      N/A           N/A\n",
      "Convolutional Layer  [  1  10  10 320]      32001         3200000\n",
      "Convolutional Layer  [   1   10   10 1280]  128001        12800000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Unknown Layer Type   [  1  10  10   2 128]  N/A           N/A\n",
      "Unknown Layer Type   [  1  10  20 128]      N/A           N/A\n",
      "Unknown Layer Type   [  1  10   2  20 128]  N/A           N/A\n",
      "Unknown Layer Type   [  1  20  20 128]      N/A           N/A\n",
      "Unknown Layer Type   [  1  20  20 128]      N/A           N/A\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Unknown Layer Type   [  1  20  20   2 128]  N/A           N/A\n",
      "Unknown Layer Type   [  1  20  40 128]      N/A           N/A\n",
      "Unknown Layer Type   [  1  20   2  40 128]  N/A           N/A\n",
      "Unknown Layer Type   [  1  40  40 128]      N/A           N/A\n",
      "Unknown Layer Type   [  1  40  40 128]      N/A           N/A\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [ 1 40 40 24]          38401         61440000\n",
      "Convolutional Layer  [   1 9600    4]       2             N/A\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [ 1 20 20 24]          9601          3840000\n",
      "Convolutional Layer  [   1 2400    4]       2             N/A\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [ 1 10 10 24]          2401          240000\n",
      "Convolutional Layer  [  1 600   4]          2             N/A\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [ 1  5  5 24]          601           15000\n",
      "Convolutional Layer  [  1 150   4]          2             N/A\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [ 1  3  3 24]          217           1944\n",
      "Convolutional Layer  [ 1 54  4]             2             N/A\n",
      "Unknown Layer Type   [    1 12804     4]    N/A           N/A\n",
      "Convolutional Layer  [  1  40  40 128]      204801        327680000\n",
      "Convolutional Layer  [ 1 40 40 30]          48001         76800000\n",
      "Convolutional Layer  [   1 9600    5]       2             N/A\n",
      "Convolutional Layer  [  1  20  20 128]      51201         20480000\n",
      "Convolutional Layer  [ 1 20 20 30]          12001         4800000\n",
      "Convolutional Layer  [   1 2400    5]       2             N/A\n",
      "Convolutional Layer  [  1  10  10 128]      12801         1280000\n",
      "Convolutional Layer  [ 1 10 10 30]          3001          300000\n",
      "Convolutional Layer  [  1 600   5]          2             N/A\n",
      "Convolutional Layer  [  1   5   5 128]      3201          80000\n",
      "Convolutional Layer  [ 1  5  5 30]          751           18750\n",
      "Convolutional Layer  [  1 150   5]          2             N/A\n",
      "Convolutional Layer  [  1   3   3 128]      1153          10368\n",
      "Convolutional Layer  [ 1  3  3 30]          271           2430\n",
      "Convolutional Layer  [ 1 54  5]             2             N/A\n",
      "Unknown Layer Type   [    1 12804     5]    N/A           N/A\n",
      "Convolutional Layer  [    1 12804     5]    2             N/A\n",
      "Unknown Layer Type   [ 1 10  4]             N/A           N/A\n",
      "Unknown Layer Type   [ 1 10]                N/A           N/A\n",
      "Unknown Layer Type   [ 1 10]                N/A           N/A\n",
      "Unknown Layer Type   [1]                    N/A           N/A\n",
      "Unknown Layer Type   [12804     4]          N/A           N/A\n",
      "Unknown Layer Type   [12804     5]          N/A           N/A\n",
      "Unknown Layer Type   [27 32]                N/A           N/A\n",
      "Unknown Layer Type   [32 16]                N/A           N/A\n",
      "Unknown Layer Type   [16 96]                N/A           N/A\n",
      "Unknown Layer Type   [96 24]                N/A           N/A\n",
      "Unknown Layer Type   [ 24 144]              N/A           N/A\n",
      "Unknown Layer Type   [144  24]              N/A           N/A\n",
      "Unknown Layer Type   [ 24 144]              N/A           N/A\n",
      "Unknown Layer Type   [144  32]              N/A           N/A\n",
      "Unknown Layer Type   [ 32 192]              N/A           N/A\n",
      "Unknown Layer Type   [192  32]              N/A           N/A\n",
      "Unknown Layer Type   [ 32 192]              N/A           N/A\n",
      "Unknown Layer Type   [192  32]              N/A           N/A\n",
      "Unknown Layer Type   [ 32 128]              N/A           N/A\n",
      "Unknown Layer Type   [ 32 192]              N/A           N/A\n",
      "Unknown Layer Type   [192  64]              N/A           N/A\n",
      "Unknown Layer Type   [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type   [384  64]              N/A           N/A\n",
      "Unknown Layer Type   [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type   [384  64]              N/A           N/A\n",
      "Unknown Layer Type   [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type   [384  64]              N/A           N/A\n",
      "Unknown Layer Type   [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type   [384  96]              N/A           N/A\n",
      "Unknown Layer Type   [ 96 576]              N/A           N/A\n",
      "Unknown Layer Type   [576  96]              N/A           N/A\n",
      "Unknown Layer Type   [ 96 576]              N/A           N/A\n",
      "Unknown Layer Type   [576  96]              N/A           N/A\n",
      "Unknown Layer Type   [ 96 128]              N/A           N/A\n",
      "Unknown Layer Type   [ 96 576]              N/A           N/A\n",
      "Unknown Layer Type   [576 160]              N/A           N/A\n",
      "Unknown Layer Type   [160 960]              N/A           N/A\n",
      "Unknown Layer Type   [960 160]              N/A           N/A\n",
      "Unknown Layer Type   [160 960]              N/A           N/A\n",
      "Unknown Layer Type   [960 160]              N/A           N/A\n",
      "Unknown Layer Type   [160 960]              N/A           N/A\n",
      "Unknown Layer Type   [960 320]              N/A           N/A\n",
      "Unknown Layer Type   [ 320 1280]            N/A           N/A\n",
      "Unknown Layer Type   [1280  128]            N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128 128]              N/A           N/A\n",
      "Unknown Layer Type   [128  24]              N/A           N/A\n",
      "Unknown Layer Type   [128  24]              N/A           N/A\n",
      "Unknown Layer Type   [128  24]              N/A           N/A\n",
      "Unknown Layer Type   [128  24]              N/A           N/A\n",
      "Unknown Layer Type   [128  24]              N/A           N/A\n",
      "Unknown Layer Type   [128  30]              N/A           N/A\n",
      "Unknown Layer Type   [128  30]              N/A           N/A\n",
      "Unknown Layer Type   [128  30]              N/A           N/A\n",
      "Unknown Layer Type   [128  30]              N/A           N/A\n",
      "Unknown Layer Type   [128  30]              N/A           N/A\n",
      "Total Parameters: 16734547\n",
      "Total FLOPs: 140108809388\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from decimal import Decimal\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Initialize table data\n",
    "table_data = []\n",
    "\n",
    "# Get details of all layers\n",
    "total_params = Decimal(0)  # Use Decimal for total_params to handle larger values\n",
    "total_flops = Decimal(0)  # Use Decimal for total_flops to handle larger values\n",
    "\n",
    "for i, layer in enumerate(interpreter.get_tensor_details()):\n",
    "    layer_name = layer['name']\n",
    "    layer_output_shape = layer['shape']\n",
    "\n",
    "    if len(layer_output_shape) > 0:  # Check if the layer has output shape\n",
    "        layer_type = None\n",
    "        \n",
    "        # Check for specific keywords in the layer name to determine the type\n",
    "        if 'conv' in layer_name.lower():\n",
    "            layer_type = 'Convolutional Layer'\n",
    "        elif 'dense' in layer_name.lower() or 'fullyconnected' in layer_name.lower():\n",
    "            layer_type = 'Fully Connected Layer'\n",
    "        # Add more conditions for other types of layers as needed\n",
    "\n",
    "        if layer_type:\n",
    "            # Count parameters and FLOPs for convolutional layers\n",
    "            if 'conv2d' in layer_name.lower():\n",
    "                if len(layer_output_shape) >= 4:  # Check if the shape has enough dimensions\n",
    "                    filter_shape = layer_output_shape[1:3]\n",
    "                    in_channels = layer_output_shape[3]\n",
    "                    out_channels = layer_output_shape[0]\n",
    "                    kernel_size = int(filter_shape[0]) * int(filter_shape[1])\n",
    "\n",
    "                    # Convert numpy integers to regular integers before conversion to Decimal\n",
    "                    params = Decimal(int(kernel_size * in_channels) * int(out_channels) + int(out_channels))  # Weight + bias\n",
    "                    flops = Decimal(int(kernel_size * in_channels) * int(out_channels) * int(layer_output_shape[1]) * int(layer_output_shape[2]))  # MACs\n",
    "\n",
    "                    total_params += params\n",
    "                    total_flops += flops\n",
    "                    \n",
    "                    table_data.append([layer_type, layer_output_shape, params, flops])\n",
    "                else:\n",
    "                    table_data.append([layer_type, layer_output_shape, \"N/A\", \"N/A\"])\n",
    "            else:\n",
    "                # Assuming other layers (e.g., fully connected) have only bias parameters\n",
    "                params = Decimal(int(layer_output_shape[0]) + 1)  # Bias only\n",
    "                flops = \"N/A\"  # FLOPs calculation not possible without more info\n",
    "\n",
    "                total_params += params\n",
    "\n",
    "                table_data.append([layer_type, layer_output_shape, params, flops])\n",
    "        else:\n",
    "            table_data.append([\"Unknown Layer Type\", layer_output_shape, \"N/A\", \"N/A\"])\n",
    "    else:\n",
    "        table_data.append([\"Unknown Layer Type\", layer_name, \"N/A\", \"N/A\"])\n",
    "\n",
    "# Print the table without warnings\n",
    "headers = [\"Layer Type\", \"Output Shape\", \"Parameters\", \"FLOPs\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"plain\"))\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Total FLOPs: {total_flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type                    Output Shape           Parameters    FLOPs\n",
      "Unknown Layer Type            [  1 320 320   3]      N/A           N/A\n",
      "Convolutional Layer           [3]                    4             N/A\n",
      "Convolutional Layer           [3]                    4             N/A\n",
      "Unknown Layer Type            [12804     4]          N/A           N/A\n",
      "Unknown Layer Type            [4]                    N/A           N/A\n",
      "Unknown Layer Type            [4]                    N/A           N/A\n",
      "Unknown Layer Type            [4]                    N/A           N/A\n",
      "Unknown Layer Type            [4]                    N/A           N/A\n",
      "Convolutional Layer           [32]                   33            N/A\n",
      "Convolutional Layer           [32]                   33            N/A\n",
      "Unknown Layer Type            [96]                   N/A           N/A\n",
      "Unknown Layer Type            [96]                   N/A           N/A\n",
      "Unknown Layer Type            [144]                  N/A           N/A\n",
      "Unknown Layer Type            [144]                  N/A           N/A\n",
      "Unknown Layer Type            [144]                  N/A           N/A\n",
      "Unknown Layer Type            [144]                  N/A           N/A\n",
      "Unknown Layer Type            [192]                  N/A           N/A\n",
      "Unknown Layer Type            [192]                  N/A           N/A\n",
      "Unknown Layer Type            [192]                  N/A           N/A\n",
      "Unknown Layer Type            [192]                  N/A           N/A\n",
      "Unknown Layer Type            [192]                  N/A           N/A\n",
      "Unknown Layer Type            [192]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [384]                  N/A           N/A\n",
      "Unknown Layer Type            [576]                  N/A           N/A\n",
      "Unknown Layer Type            [576]                  N/A           N/A\n",
      "Unknown Layer Type            [576]                  N/A           N/A\n",
      "Unknown Layer Type            [576]                  N/A           N/A\n",
      "Unknown Layer Type            [576]                  N/A           N/A\n",
      "Unknown Layer Type            [576]                  N/A           N/A\n",
      "Unknown Layer Type            [960]                  N/A           N/A\n",
      "Unknown Layer Type            [960]                  N/A           N/A\n",
      "Unknown Layer Type            [960]                  N/A           N/A\n",
      "Unknown Layer Type            [960]                  N/A           N/A\n",
      "Unknown Layer Type            [960]                  N/A           N/A\n",
      "Unknown Layer Type            [960]                  N/A           N/A\n",
      "Convolutional Layer           [1280]                 1281          N/A\n",
      "Unknown Layer Type            [128]                  N/A           N/A\n",
      "Unknown Layer Type            [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [16]                   N/A           N/A\n",
      "Convolutional Layer           [24]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 144]      N/A           N/A\n",
      "Convolutional Layer           [24]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 144]      N/A           N/A\n",
      "Convolutional Layer           [32]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 192]      N/A           N/A\n",
      "Convolutional Layer           [32]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 192]      N/A           N/A\n",
      "Convolutional Layer           [32]                   N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 192]      N/A           N/A\n",
      "Convolutional Layer           [64]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer           [64]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer           [64]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer           [64]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 384]      N/A           N/A\n",
      "Convolutional Layer           [96]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 576]      N/A           N/A\n",
      "Convolutional Layer           [96]                   N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 576]      N/A           N/A\n",
      "Convolutional Layer           [96]                   N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 576]      N/A           N/A\n",
      "Convolutional Layer           [160]                  N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 960]      N/A           N/A\n",
      "Convolutional Layer           [160]                  N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 960]      N/A           N/A\n",
      "Convolutional Layer           [160]                  N/A           N/A\n",
      "Unknown Layer Type            [  1   3   3 960]      N/A           N/A\n",
      "Convolutional Layer           [320]                  N/A           N/A\n",
      "Convolutional Layer           [128]                  N/A           N/A\n",
      "Convolutional Layer           [24]                   N/A           N/A\n",
      "Convolutional Layer           [30]                   N/A           N/A\n",
      "Unknown Layer Type            [  1  80  80 144]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 80 80 24]          N/A           N/A\n",
      "Unknown Layer Type            [  1  40  40 144]      N/A           N/A\n",
      "Unknown Layer Type            [  1  40  40 192]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 40 40 32]          N/A           N/A\n",
      "Unknown Layer Type            [  1  40  40 192]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 40 40 32]          N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 192]      N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 384]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 20 20 64]          N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 384]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 20 20 64]          N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 384]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 20 20 64]          N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 384]      N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 576]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 20 20 96]          N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 576]      N/A           N/A\n",
      "Unknown Layer Type            [ 1 20 20 96]          N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10 576]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10 960]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10 160]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10 960]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10 160]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10 960]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10  10   2 128]  N/A           N/A\n",
      "Unknown Layer Type            [  1  10  20 128]      N/A           N/A\n",
      "Unknown Layer Type            [  1  10   2  20 128]  N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 128]      N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20 128]      N/A           N/A\n",
      "Unknown Layer Type            [  1  20  20   2 128]  N/A           N/A\n",
      "Unknown Layer Type            [  1  20  40 128]      N/A           N/A\n",
      "Unknown Layer Type            [  1  20   2  40 128]  N/A           N/A\n",
      "Unknown Layer Type            [  1  40  40 128]      N/A           N/A\n",
      "Unknown Layer Type            [  1  40  40 128]      N/A           N/A\n",
      "Convolutional Layer           [   1 9600    4]       2             N/A\n",
      "Convolutional Layer           [   1 2400    4]       2             N/A\n",
      "Convolutional Layer           [  1 600   4]          2             N/A\n",
      "Convolutional Layer           [  1 150   4]          2             N/A\n",
      "Convolutional Layer           [ 1 54  4]             2             N/A\n",
      "Unknown Layer Type            [    1 12804     4]    N/A           N/A\n",
      "Convolutional Layer           [   1 9600    5]       2             N/A\n",
      "Convolutional Layer           [   1 2400    5]       2             N/A\n",
      "Convolutional Layer           [  1 600   5]          2             N/A\n",
      "Convolutional Layer           [  1 150   5]          2             N/A\n",
      "Convolutional Layer           [ 1 54  5]             2             N/A\n",
      "Unknown Layer Type            [    1 12804     5]    N/A           N/A\n",
      "Convolutional Layer           [    1 12804     5]    2             N/A\n",
      "Unknown Layer Type            [ 1 10  4]             N/A           N/A\n",
      "Unknown Layer Type            [ 1 10]                N/A           N/A\n",
      "Unknown Layer Type            [ 1 10]                N/A           N/A\n",
      "Unknown Layer Type            [1]                    N/A           N/A\n",
      "Unknown Layer Type            [12804     4]          N/A           N/A\n",
      "Unknown Layer Type            [12804     5]          N/A           N/A\n",
      "Unknown Layer Type            [27 32]                N/A           N/A\n",
      "Unknown Layer Type            [32 16]                N/A           N/A\n",
      "Unknown Layer Type            [16 96]                N/A           N/A\n",
      "Unknown Layer Type            [96 24]                N/A           N/A\n",
      "Unknown Layer Type            [ 24 144]              N/A           N/A\n",
      "Unknown Layer Type            [144  24]              N/A           N/A\n",
      "Unknown Layer Type            [ 24 144]              N/A           N/A\n",
      "Unknown Layer Type            [144  32]              N/A           N/A\n",
      "Unknown Layer Type            [ 32 192]              N/A           N/A\n",
      "Unknown Layer Type            [192  32]              N/A           N/A\n",
      "Unknown Layer Type            [ 32 192]              N/A           N/A\n",
      "Unknown Layer Type            [192  32]              N/A           N/A\n",
      "Unknown Layer Type            [ 32 128]              N/A           N/A\n",
      "Unknown Layer Type            [ 32 192]              N/A           N/A\n",
      "Unknown Layer Type            [192  64]              N/A           N/A\n",
      "Unknown Layer Type            [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type            [384  64]              N/A           N/A\n",
      "Unknown Layer Type            [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type            [384  64]              N/A           N/A\n",
      "Unknown Layer Type            [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type            [384  64]              N/A           N/A\n",
      "Unknown Layer Type            [ 64 384]              N/A           N/A\n",
      "Unknown Layer Type            [384  96]              N/A           N/A\n",
      "Unknown Layer Type            [ 96 576]              N/A           N/A\n",
      "Unknown Layer Type            [576  96]              N/A           N/A\n",
      "Unknown Layer Type            [ 96 576]              N/A           N/A\n",
      "Unknown Layer Type            [576  96]              N/A           N/A\n",
      "Unknown Layer Type            [ 96 128]              N/A           N/A\n",
      "Unknown Layer Type            [ 96 576]              N/A           N/A\n",
      "Unknown Layer Type            [576 160]              N/A           N/A\n",
      "Unknown Layer Type            [160 960]              N/A           N/A\n",
      "Unknown Layer Type            [960 160]              N/A           N/A\n",
      "Unknown Layer Type            [160 960]              N/A           N/A\n",
      "Unknown Layer Type            [960 160]              N/A           N/A\n",
      "Unknown Layer Type            [160 960]              N/A           N/A\n",
      "Unknown Layer Type            [960 320]              N/A           N/A\n",
      "Unknown Layer Type            [ 320 1280]            N/A           N/A\n",
      "Unknown Layer Type            [1280  128]            N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128 128]              N/A           N/A\n",
      "Unknown Layer Type            [128  24]              N/A           N/A\n",
      "Unknown Layer Type            [128  24]              N/A           N/A\n",
      "Unknown Layer Type            [128  24]              N/A           N/A\n",
      "Unknown Layer Type            [128  24]              N/A           N/A\n",
      "Unknown Layer Type            [128  24]              N/A           N/A\n",
      "Unknown Layer Type            [128  30]              N/A           N/A\n",
      "Unknown Layer Type            [128  30]              N/A           N/A\n",
      "Unknown Layer Type            [128  30]              N/A           N/A\n",
      "Unknown Layer Type            [128  30]              N/A           N/A\n",
      "Unknown Layer Type            [128  30]              N/A           N/A\n",
      "Convolutional Layers (Total)  N/A                    16733170      140108809388\n",
      "Total Parameters: 16734547\n",
      "Total FLOPs: 140108809388\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from decimal import Decimal\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Initialize table data\n",
    "table_data = []\n",
    "\n",
    "# Get details of all layers\n",
    "total_params = Decimal(0)  # Use Decimal for total_params to handle larger values\n",
    "total_flops = Decimal(0)  # Use Decimal for total_flops to handle larger values\n",
    "conv_params = Decimal(0)  # Accumulator for convolutional layer parameters\n",
    "conv_flops = Decimal(0)  # Accumulator for convolutional layer FLOPs\n",
    "\n",
    "for i, layer in enumerate(interpreter.get_tensor_details()):\n",
    "    layer_name = layer['name']\n",
    "    layer_output_shape = layer['shape']\n",
    "\n",
    "    if len(layer_output_shape) > 0:  # Check if the layer has output shape\n",
    "        layer_type = None\n",
    "        \n",
    "        # Check for specific keywords in the layer name to determine the type\n",
    "        if 'conv' in layer_name.lower():\n",
    "            layer_type = 'Convolutional Layer'\n",
    "        elif 'dwise' in layer_name.lower() or 'fullyconnected' in layer_name.lower():\n",
    "            layer_type = 'Fully Connected Layer'\n",
    "        elif 'pool' in layer_name.lower():\n",
    "            layer_type = 'Pooling Layer'\n",
    "        elif 'activation' in layer_name.lower():\n",
    "            layer_type = 'Activation Layer'\n",
    "        elif 'dropout' in layer_name.lower():\n",
    "            layer_type = 'Dropout Layer'\n",
    "        elif 'flatten' in layer_name.lower():\n",
    "            layer_type = 'Flatten Layer'\n",
    "        # Add more conditions for other types of layers as needed\n",
    "\n",
    "        if layer_type:\n",
    "            # Count parameters and FLOPs for convolutional layers\n",
    "            if 'conv2d' in layer_name.lower():\n",
    "                if len(layer_output_shape) >= 4:  # Check if the shape has enough dimensions\n",
    "                    filter_shape = layer_output_shape[1:3]\n",
    "                    in_channels = layer_output_shape[3]\n",
    "                    out_channels = layer_output_shape[0]\n",
    "                    kernel_size = int(filter_shape[0]) * int(filter_shape[1])\n",
    "\n",
    "                    # Convert numpy integers to regular integers before conversion to Decimal\n",
    "                    params = Decimal(int(kernel_size * in_channels) * int(out_channels) + int(out_channels))  # Weight + bias\n",
    "                    flops = Decimal(int(kernel_size * in_channels) * int(out_channels) * int(layer_output_shape[1]) * int(layer_output_shape[2]))  # MACs\n",
    "\n",
    "                    total_params += params\n",
    "                    total_flops += flops\n",
    "                    conv_params += params\n",
    "                    conv_flops += flops\n",
    "                else:\n",
    "                    table_data.append([layer_type, layer_output_shape, \"N/A\", \"N/A\"])\n",
    "            else:\n",
    "                # Assuming other layers (e.g., fully connected) have only bias parameters\n",
    "                params = Decimal(int(layer_output_shape[0]) + 1)  # Bias only\n",
    "                flops = \"N/A\"  # FLOPs calculation not possible without more info\n",
    "\n",
    "                total_params += params\n",
    "\n",
    "                table_data.append([layer_type, layer_output_shape, params, flops])\n",
    "        else:\n",
    "            table_data.append([\"Unknown Layer Type\", layer_output_shape, \"N/A\", \"N/A\"])\n",
    "    else:\n",
    "        table_data.append([\"Unknown Layer Type\", layer_name, \"N/A\", \"N/A\"])\n",
    "\n",
    "# Add a single entry for all convolutional layers\n",
    "table_data.append([\"Convolutional Layers (Total)\", \"N/A\", conv_params, conv_flops])\n",
    "\n",
    "# Print the table without warnings\n",
    "headers = [\"Layer Type\", \"Output Shape\", \"Parameters\", \"FLOPs\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"plain\"))\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Total FLOPs: {total_flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading SavedModel: SavedModel file does not exist at: C:/UsersAI/Desktop/Tensorflow/custom_model_lite/saved_model/\\{saved_model.pbtxt|saved_model.pb}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Path to the directory containing the SavedModel\n",
    "model_dir = \"C:/UsersAI/Desktop/Tensorflow/custom_model_lite/saved_model/\"\n",
    "\n",
    "try:\n",
    "    # Load the SavedModel\n",
    "    loaded_model = tf.saved_model.load(model_dir)\n",
    "\n",
    "    # Print available information\n",
    "    print(\"SavedModel loaded successfully!\")\n",
    "\n",
    "    # Print signatures\n",
    "    print(\"Signatures:\")\n",
    "    for signature_name in loaded_model.signatures:\n",
    "        signature = loaded_model.signatures[signature_name]\n",
    "        print(f\"- {signature_name}:\")\n",
    "        print(f\"  - Inputs: {signature.inputs}\")\n",
    "        print(f\"  - Outputs: {signature.outputs}\")\n",
    "\n",
    "    # Print computational graph structure\n",
    "    print(\"Computational Graph Structure:\")\n",
    "    print(loaded_model.graph.as_graph_def())\n",
    "\n",
    "    # Print metadata (if available)\n",
    "    if hasattr(loaded_model, \"metadata\"):\n",
    "        print(\"Metadata:\")\n",
    "        print(loaded_model.metadata)\n",
    "\n",
    "    # Access input and output tensors (if needed)\n",
    "    # input_tensor = loaded_model.input_tensor\n",
    "    # output_tensor = loaded_model.output_tensor\n",
    "\n",
    "    # Access model parameters (if applicable)\n",
    "    # model_parameters = loaded_model.trainable_variables\n",
    "\n",
    "    # Perform specific tasks with the model (e.g., make predictions)\n",
    "\n",
    "except OSError as e:\n",
    "    print(f\"Error loading SavedModel: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot set tensor: Dimension mismatch. Got 2 but expected 4 for input 0.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m2.0\u001b[39m, \u001b[38;5;241m3.0\u001b[39m], [\u001b[38;5;241m4.0\u001b[39m, \u001b[38;5;241m5.0\u001b[39m, \u001b[38;5;241m6.0\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Set input tensor\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43minterpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_details\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Run inference\u001b[39;00m\n\u001b[0;32m     18\u001b[0m interpreter\u001b[38;5;241m.\u001b[39minvoke()\n",
      "File \u001b[1;32mc:\\Users\\AI\\miniconda3\\envs\\face-algo\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py:697\u001b[0m, in \u001b[0;36mInterpreter.set_tensor\u001b[1;34m(self, tensor_index, value)\u001b[0m\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_tensor\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor_index, value):\n\u001b[0;32m    682\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of the input tensor.\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \n\u001b[0;32m    684\u001b[0m \u001b[38;5;124;03m  Note this copies data in `value`.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03m    ValueError: If the interpreter could not set the tensor.\u001b[39;00m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 697\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpreter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSetTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot set tensor: Dimension mismatch. Got 2 but expected 4 for input 0."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input details\n",
    "input_details = interpreter.get_input_details()\n",
    "\n",
    "# Prepare example input data\n",
    "input_data = np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=np.float32)\n",
    "\n",
    "# Set input tensor\n",
    "interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "# Run inference\n",
    "interpreter.invoke()\n",
    "\n",
    "# Get output details and results\n",
    "output_details = interpreter.get_output_details()\n",
    "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "print(output_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type                         Total Parameters    Total FLOPs\n",
      "Convolution Layer                       3.30622e+06    1.08417e+10\n",
      "Shape Layer                            28              0\n",
      "Depthwise Convolution Layer             1.26687e+07    1.27153e+11\n",
      "Fused Batch Normalization Layer     14558              0\n",
      "Separable Convolution Layer        759654              2.11387e+09\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from decimal import Decimal\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Initialize dictionaries to store layer-wise parameters and FLOPs\n",
    "layer_params = {}\n",
    "layer_flops = {}\n",
    "\n",
    "# Get details of all layers\n",
    "for i, layer in enumerate(interpreter.get_tensor_details()):\n",
    "    layer_name = layer['name']\n",
    "    layer_output_shape = layer['shape']\n",
    "\n",
    "    if len(layer_output_shape) > 0:  # Check if the layer has output shape\n",
    "        layer_type = None\n",
    "        \n",
    "        # Check for specific keywords in the layer name to determine the type\n",
    "        if 'conv' in layer_name.lower():\n",
    "            if 'depthwise' in layer_name.lower():\n",
    "                layer_type = 'Depthwise Convolution Layer'\n",
    "            elif 'separable_conv2d' in layer_name.lower():\n",
    "                layer_type = 'Separable Convolution Layer'\n",
    "            else:\n",
    "                layer_type = 'Convolution Layer'\n",
    "        elif 'dense' in layer_name.lower() or 'fullyconnected' in layer_name.lower():\n",
    "            layer_type = 'Fully Connected Layer'\n",
    "        elif 'fusedbatchnormv3' in layer_name.lower():\n",
    "            layer_type = 'Fused Batch Normalization Layer'\n",
    "        elif 'readvariableop' in layer_name.lower():\n",
    "            layer_type = 'Read Variable Operation'\n",
    "        elif 'readvariableop1' in layer_name.lower():\n",
    "            layer_type = 'Read Variable Operation 1'\n",
    "        elif 'shape' in layer_name.lower():\n",
    "            layer_type = 'Shape Layer'\n",
    "        # Add more conditions for other types of layers as needed\n",
    "\n",
    "        if layer_type:\n",
    "            # Initialize layer-wise parameters and FLOPs\n",
    "            if layer_type not in layer_params:\n",
    "                layer_params[layer_type] = Decimal(0)\n",
    "                layer_flops[layer_type] = Decimal(0)\n",
    "\n",
    "            # Count parameters and FLOPs for convolutional layers\n",
    "            if 'conv2d' in layer_name.lower() or 'depthwiseconv2d' in layer_name.lower() or 'separableconv2d' in layer_name.lower():\n",
    "                if len(layer_output_shape) >= 4:  # Check if the shape has enough dimensions\n",
    "                    filter_shape = layer_output_shape[1:3]\n",
    "                    in_channels = layer_output_shape[3]\n",
    "                    out_channels = layer_output_shape[0]\n",
    "                    kernel_size = int(filter_shape[0]) * int(filter_shape[1])\n",
    "\n",
    "                    # Convert numpy integers to regular integers before conversion to Decimal\n",
    "                    params = Decimal(int(kernel_size * in_channels) * int(out_channels) + int(out_channels))  # Weight + bias\n",
    "                    flops = Decimal(int(kernel_size * in_channels) * int(out_channels) * int(layer_output_shape[1]) * int(layer_output_shape[2]))  # MACs\n",
    "\n",
    "                    layer_params[layer_type] += params\n",
    "                    layer_flops[layer_type] += flops\n",
    "                else:\n",
    "                    layer_params[layer_type] += Decimal(0)\n",
    "                    layer_flops[layer_type] += Decimal(0)\n",
    "            else:\n",
    "                # Assuming other layers (e.g., fully connected) have only bias parameters\n",
    "                params = Decimal(int(layer_output_shape[0]) + 1)  # Bias only\n",
    "                flops = Decimal(0)  # FLOPs calculation not relevant for non-convolutional layers\n",
    "\n",
    "                layer_params[layer_type] += params\n",
    "\n",
    "# Generate the final table for each layer type\n",
    "table_data = []\n",
    "for layer_type, params in layer_params.items():\n",
    "    flops = layer_flops.get(layer_type, Decimal(0))\n",
    "    table_data.append([layer_type, params, flops])\n",
    "\n",
    "# Print the final table\n",
    "headers = [\"Layer Type\", \"Total Parameters\", \"Total FLOPs\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"plain\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type                       Output Shape           Parameters    FLOPs        Layer Shape\n",
      "Unknown Layer Type               [  1 320 320   3]      N/A           N/A          [  1 320 320   3]\n",
      "Convolution Layer                [3]                    4             N/A          [3]\n",
      "Convolution Layer                [3]                    4             N/A          [3]\n",
      "Unknown Layer Type               [12804     4]          N/A           N/A          [12804     4]\n",
      "Shape Layer                      [4]                    5             N/A          [4]\n",
      "Shape Layer                      [4]                    5             N/A          [4]\n",
      "Shape Layer                      [4]                    5             N/A          [4]\n",
      "Shape Layer                      [4]                    5             N/A          [4]\n",
      "Convolution Layer                [32]                   33            N/A          [32]\n",
      "Depthwise Convolution Layer      [32]                   33            N/A          [32]\n",
      "Fused Batch Normalization Layer  [96]                   97            N/A          [96]\n",
      "Fused Batch Normalization Layer  [96]                   97            N/A          [96]\n",
      "Fused Batch Normalization Layer  [144]                  145           N/A          [144]\n",
      "Fused Batch Normalization Layer  [144]                  145           N/A          [144]\n",
      "Fused Batch Normalization Layer  [144]                  145           N/A          [144]\n",
      "Fused Batch Normalization Layer  [144]                  145           N/A          [144]\n",
      "Fused Batch Normalization Layer  [192]                  193           N/A          [192]\n",
      "Fused Batch Normalization Layer  [192]                  193           N/A          [192]\n",
      "Fused Batch Normalization Layer  [192]                  193           N/A          [192]\n",
      "Fused Batch Normalization Layer  [192]                  193           N/A          [192]\n",
      "Fused Batch Normalization Layer  [192]                  193           N/A          [192]\n",
      "Fused Batch Normalization Layer  [192]                  193           N/A          [192]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [384]                  385           N/A          [384]\n",
      "Fused Batch Normalization Layer  [576]                  577           N/A          [576]\n",
      "Fused Batch Normalization Layer  [576]                  577           N/A          [576]\n",
      "Fused Batch Normalization Layer  [576]                  577           N/A          [576]\n",
      "Fused Batch Normalization Layer  [576]                  577           N/A          [576]\n",
      "Fused Batch Normalization Layer  [576]                  577           N/A          [576]\n",
      "Fused Batch Normalization Layer  [576]                  577           N/A          [576]\n",
      "Fused Batch Normalization Layer  [960]                  961           N/A          [960]\n",
      "Fused Batch Normalization Layer  [960]                  961           N/A          [960]\n",
      "Fused Batch Normalization Layer  [960]                  961           N/A          [960]\n",
      "Fused Batch Normalization Layer  [960]                  961           N/A          [960]\n",
      "Fused Batch Normalization Layer  [960]                  961           N/A          [960]\n",
      "Fused Batch Normalization Layer  [960]                  961           N/A          [960]\n",
      "Convolution Layer                [1280]                 1281          N/A          [1280]\n",
      "Fused Batch Normalization Layer  [128]                  129           N/A          [128]\n",
      "Fused Batch Normalization Layer  [128]                  129           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [32  3  3  3]          896           7776         [32  3  3  3]\n",
      "Convolution Layer                [16  1  1 32]          528           512          [16  1  1 32]\n",
      "Convolution Layer                [96  1  1 16]          1632          1536         [96  1  1 16]\n",
      "Convolution Layer                [24  1  1 96]          2328          2304         [24  1  1 96]\n",
      "Convolution Layer                [144   1   1  24]      3600          3456         [144   1   1  24]\n",
      "Convolution Layer                [ 24   1   1 144]      3480          3456         [ 24   1   1 144]\n",
      "Convolution Layer                [144   1   1  24]      3600          3456         [144   1   1  24]\n",
      "Convolution Layer                [ 32   1   1 144]      4640          4608         [ 32   1   1 144]\n",
      "Convolution Layer                [192   1   1  32]      6336          6144         [192   1   1  32]\n",
      "Convolution Layer                [ 32   1   1 192]      6176          6144         [ 32   1   1 192]\n",
      "Convolution Layer                [192   1   1  32]      6336          6144         [192   1   1  32]\n",
      "Convolution Layer                [ 32   1   1 192]      6176          6144         [ 32   1   1 192]\n",
      "Depthwise Convolution Layer      [128]                  N/A           N/A          [128]\n",
      "Convolution Layer                [128   1   1  32]      4224          4096         [128   1   1  32]\n",
      "Convolution Layer                [192   1   1  32]      6336          6144         [192   1   1  32]\n",
      "Convolution Layer                [ 64   1   1 192]      12352         12288        [ 64   1   1 192]\n",
      "Convolution Layer                [384   1   1  64]      24960         24576        [384   1   1  64]\n",
      "Convolution Layer                [ 64   1   1 384]      24640         24576        [ 64   1   1 384]\n",
      "Convolution Layer                [384   1   1  64]      24960         24576        [384   1   1  64]\n",
      "Convolution Layer                [ 64   1   1 384]      24640         24576        [ 64   1   1 384]\n",
      "Convolution Layer                [384   1   1  64]      24960         24576        [384   1   1  64]\n",
      "Convolution Layer                [ 64   1   1 384]      24640         24576        [ 64   1   1 384]\n",
      "Convolution Layer                [384   1   1  64]      24960         24576        [384   1   1  64]\n",
      "Convolution Layer                [ 96   1   1 384]      36960         36864        [ 96   1   1 384]\n",
      "Convolution Layer                [576   1   1  96]      55872         55296        [576   1   1  96]\n",
      "Convolution Layer                [ 96   1   1 576]      55392         55296        [ 96   1   1 576]\n",
      "Convolution Layer                [576   1   1  96]      55872         55296        [576   1   1  96]\n",
      "Convolution Layer                [ 96   1   1 576]      55392         55296        [ 96   1   1 576]\n",
      "Convolution Layer                [128   1   1  96]      12416         12288        [128   1   1  96]\n",
      "Convolution Layer                [576   1   1  96]      55872         55296        [576   1   1  96]\n",
      "Convolution Layer                [160   1   1 576]      92320         92160        [160   1   1 576]\n",
      "Convolution Layer                [960   1   1 160]      154560        153600       [960   1   1 160]\n",
      "Convolution Layer                [160   1   1 960]      153760        153600       [160   1   1 960]\n",
      "Convolution Layer                [960   1   1 160]      154560        153600       [960   1   1 160]\n",
      "Convolution Layer                [160   1   1 960]      153760        153600       [160   1   1 960]\n",
      "Convolution Layer                [960   1   1 160]      154560        153600       [960   1   1 160]\n",
      "Convolution Layer                [320   1   1 960]      307520        307200       [320   1   1 960]\n",
      "Convolution Layer                [1280    1    1  320]  410880        409600       [1280    1    1  320]\n",
      "Convolution Layer                [ 128    1    1 1280]  163968        163840       [ 128    1    1 1280]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 1    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 2    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 3    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 1    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 2    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 3    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 1    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 2    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 3    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 1    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 2    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer 3    [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Separable Convolution Layer      [128   1   1 128]      16512         16384        [128   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [ 24   1   1 128]      3096          3072         [ 24   1   1 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [ 30   1   1 128]      3870          3840         [ 30   1   1 128]\n",
      "Depthwise Convolution Layer      [ 1  3  3 32]          289           2592         [ 1  3  3 32]\n",
      "Convolution Layer                [16]                   N/A           N/A          [16]\n",
      "Depthwise Convolution Layer      [ 1  3  3 96]          865           7776         [ 1  3  3 96]\n",
      "Separable Convolution Layer      [24]                   N/A           N/A          [24]\n",
      "Fused Batch Normalization Layer  [  1   3   3 144]      2             N/A          [  1   3   3 144]\n",
      "Separable Convolution Layer      [24]                   N/A           N/A          [24]\n",
      "Fused Batch Normalization Layer  [  1   3   3 144]      2             N/A          [  1   3   3 144]\n",
      "Convolution Layer                [32]                   N/A           N/A          [32]\n",
      "Fused Batch Normalization Layer  [  1   3   3 192]      2             N/A          [  1   3   3 192]\n",
      "Convolution Layer                [32]                   N/A           N/A          [32]\n",
      "Fused Batch Normalization Layer  [  1   3   3 192]      2             N/A          [  1   3   3 192]\n",
      "Convolution Layer                [32]                   N/A           N/A          [32]\n",
      "Depthwise Convolution Layer      [128]                  N/A           N/A          [128]\n",
      "Fused Batch Normalization Layer  [  1   3   3 192]      2             N/A          [  1   3   3 192]\n",
      "Convolution Layer                [64]                   N/A           N/A          [64]\n",
      "Fused Batch Normalization Layer  [  1   3   3 384]      2             N/A          [  1   3   3 384]\n",
      "Convolution Layer                [64]                   N/A           N/A          [64]\n",
      "Fused Batch Normalization Layer  [  1   3   3 384]      2             N/A          [  1   3   3 384]\n",
      "Convolution Layer                [64]                   N/A           N/A          [64]\n",
      "Fused Batch Normalization Layer  [  1   3   3 384]      2             N/A          [  1   3   3 384]\n",
      "Convolution Layer                [64]                   N/A           N/A          [64]\n",
      "Fused Batch Normalization Layer  [  1   3   3 384]      2             N/A          [  1   3   3 384]\n",
      "Convolution Layer                [96]                   N/A           N/A          [96]\n",
      "Fused Batch Normalization Layer  [  1   3   3 576]      2             N/A          [  1   3   3 576]\n",
      "Convolution Layer                [96]                   N/A           N/A          [96]\n",
      "Fused Batch Normalization Layer  [  1   3   3 576]      2             N/A          [  1   3   3 576]\n",
      "Convolution Layer                [96]                   N/A           N/A          [96]\n",
      "Depthwise Convolution Layer      [128]                  N/A           N/A          [128]\n",
      "Fused Batch Normalization Layer  [  1   3   3 576]      2             N/A          [  1   3   3 576]\n",
      "Convolution Layer                [160]                  N/A           N/A          [160]\n",
      "Fused Batch Normalization Layer  [  1   3   3 960]      2             N/A          [  1   3   3 960]\n",
      "Convolution Layer                [160]                  N/A           N/A          [160]\n",
      "Fused Batch Normalization Layer  [  1   3   3 960]      2             N/A          [  1   3   3 960]\n",
      "Convolution Layer                [160]                  N/A           N/A          [160]\n",
      "Fused Batch Normalization Layer  [  1   3   3 960]      2             N/A          [  1   3   3 960]\n",
      "Convolution Layer                [320]                  N/A           N/A          [320]\n",
      "Depthwise Convolution Layer      [128]                  N/A           N/A          [128]\n",
      "Separable Convolution Layer      [24]                   N/A           N/A          [24]\n",
      "Separable Convolution Layer      [30]                   N/A           N/A          [30]\n",
      "Depthwise Convolution Layer      [  1 160 160  32]      819201        20971520000  [  1 160 160  32]\n",
      "Depthwise Convolution Layer      [  1 160 160  32]      819201        20971520000  [  1 160 160  32]\n",
      "Convolution Layer                [  1 160 160  16]      409601        10485760000  [  1 160 160  16]\n",
      "Depthwise Convolution Layer      [  1 160 160  96]      2457601       62914560000  [  1 160 160  96]\n",
      "Depthwise Convolution Layer      [ 1 80 80 96]          614401        3932160000   [ 1 80 80 96]\n",
      "Separable Convolution Layer      [ 1 80 80 24]          153601        983040000    [ 1 80 80 24]\n",
      "Depthwise Convolution Layer      [  1  80  80 144]      921601        5898240000   [  1  80  80 144]\n",
      "Fused Batch Normalization Layer  [  1  80  80 144]      2             N/A          [  1  80  80 144]\n",
      "Separable Convolution Layer      [ 1 80 80 24]          153601        983040000    [ 1 80 80 24]\n",
      "Unknown Layer Type               [ 1 80 80 24]          N/A           N/A          [ 1 80 80 24]\n",
      "Depthwise Convolution Layer      [  1  80  80 144]      921601        5898240000   [  1  80  80 144]\n",
      "Fused Batch Normalization Layer  [  1  40  40 144]      2             N/A          [  1  40  40 144]\n",
      "Convolution Layer                [ 1 40 40 32]          51201         81920000     [ 1 40 40 32]\n",
      "Depthwise Convolution Layer      [  1  40  40 192]      307201        491520000    [  1  40  40 192]\n",
      "Fused Batch Normalization Layer  [  1  40  40 192]      2             N/A          [  1  40  40 192]\n",
      "Convolution Layer                [ 1 40 40 32]          51201         81920000     [ 1 40 40 32]\n",
      "Unknown Layer Type               [ 1 40 40 32]          N/A           N/A          [ 1 40 40 32]\n",
      "Depthwise Convolution Layer      [  1  40  40 192]      307201        491520000    [  1  40  40 192]\n",
      "Fused Batch Normalization Layer  [  1  40  40 192]      2             N/A          [  1  40  40 192]\n",
      "Convolution Layer                [ 1 40 40 32]          51201         81920000     [ 1 40 40 32]\n",
      "Unknown Layer Type               [ 1 40 40 32]          N/A           N/A          [ 1 40 40 32]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 192]      307201        491520000    [  1  40  40 192]\n",
      "Fused Batch Normalization Layer  [  1  20  20 192]      2             N/A          [  1  20  20 192]\n",
      "Convolution Layer                [ 1 20 20 64]          25601         10240000     [ 1 20 20 64]\n",
      "Depthwise Convolution Layer      [  1  20  20 384]      153601        61440000     [  1  20  20 384]\n",
      "Fused Batch Normalization Layer  [  1  20  20 384]      2             N/A          [  1  20  20 384]\n",
      "Convolution Layer                [ 1 20 20 64]          25601         10240000     [ 1 20 20 64]\n",
      "Unknown Layer Type               [ 1 20 20 64]          N/A           N/A          [ 1 20 20 64]\n",
      "Depthwise Convolution Layer      [  1  20  20 384]      153601        61440000     [  1  20  20 384]\n",
      "Fused Batch Normalization Layer  [  1  20  20 384]      2             N/A          [  1  20  20 384]\n",
      "Convolution Layer                [ 1 20 20 64]          25601         10240000     [ 1 20 20 64]\n",
      "Unknown Layer Type               [ 1 20 20 64]          N/A           N/A          [ 1 20 20 64]\n",
      "Depthwise Convolution Layer      [  1  20  20 384]      153601        61440000     [  1  20  20 384]\n",
      "Fused Batch Normalization Layer  [  1  20  20 384]      2             N/A          [  1  20  20 384]\n",
      "Convolution Layer                [ 1 20 20 64]          25601         10240000     [ 1 20 20 64]\n",
      "Unknown Layer Type               [ 1 20 20 64]          N/A           N/A          [ 1 20 20 64]\n",
      "Depthwise Convolution Layer      [  1  20  20 384]      153601        61440000     [  1  20  20 384]\n",
      "Fused Batch Normalization Layer  [  1  20  20 384]      2             N/A          [  1  20  20 384]\n",
      "Convolution Layer                [ 1 20 20 96]          38401         15360000     [ 1 20 20 96]\n",
      "Depthwise Convolution Layer      [  1  20  20 576]      230401        92160000     [  1  20  20 576]\n",
      "Fused Batch Normalization Layer  [  1  20  20 576]      2             N/A          [  1  20  20 576]\n",
      "Convolution Layer                [ 1 20 20 96]          38401         15360000     [ 1 20 20 96]\n",
      "Unknown Layer Type               [ 1 20 20 96]          N/A           N/A          [ 1 20 20 96]\n",
      "Depthwise Convolution Layer      [  1  20  20 576]      230401        92160000     [  1  20  20 576]\n",
      "Fused Batch Normalization Layer  [  1  20  20 576]      2             N/A          [  1  20  20 576]\n",
      "Convolution Layer                [ 1 20 20 96]          38401         15360000     [ 1 20 20 96]\n",
      "Unknown Layer Type               [ 1 20 20 96]          N/A           N/A          [ 1 20 20 96]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 576]      230401        92160000     [  1  20  20 576]\n",
      "Fused Batch Normalization Layer  [  1  10  10 576]      2             N/A          [  1  10  10 576]\n",
      "Convolution Layer                [  1  10  10 160]      16001         1600000      [  1  10  10 160]\n",
      "Depthwise Convolution Layer      [  1  10  10 960]      96001         9600000      [  1  10  10 960]\n",
      "Fused Batch Normalization Layer  [  1  10  10 960]      2             N/A          [  1  10  10 960]\n",
      "Convolution Layer                [  1  10  10 160]      16001         1600000      [  1  10  10 160]\n",
      "Unknown Layer Type               [  1  10  10 160]      N/A           N/A          [  1  10  10 160]\n",
      "Depthwise Convolution Layer      [  1  10  10 960]      96001         9600000      [  1  10  10 960]\n",
      "Fused Batch Normalization Layer  [  1  10  10 960]      2             N/A          [  1  10  10 960]\n",
      "Convolution Layer                [  1  10  10 160]      16001         1600000      [  1  10  10 160]\n",
      "Unknown Layer Type               [  1  10  10 160]      N/A           N/A          [  1  10  10 160]\n",
      "Depthwise Convolution Layer      [  1  10  10 960]      96001         9600000      [  1  10  10 960]\n",
      "Fused Batch Normalization Layer  [  1  10  10 960]      2             N/A          [  1  10  10 960]\n",
      "Convolution Layer                [  1  10  10 320]      32001         3200000      [  1  10  10 320]\n",
      "Convolution Layer                [   1   10   10 1280]  128001        12800000     [   1   10   10 1280]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Unknown Layer Type               [  1  10  10   2 128]  N/A           N/A          [  1  10  10   2 128]\n",
      "Shape Layer                      [  1  10  20 128]      2             N/A          [  1  10  20 128]\n",
      "Unknown Layer Type               [  1  10   2  20 128]  N/A           N/A          [  1  10   2  20 128]\n",
      "Shape Layer                      [  1  20  20 128]      2             N/A          [  1  20  20 128]\n",
      "Unknown Layer Type               [  1  20  20 128]      N/A           N/A          [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Unknown Layer Type               [  1  20  20   2 128]  N/A           N/A          [  1  20  20   2 128]\n",
      "Shape Layer                      [  1  20  40 128]      2             N/A          [  1  20  40 128]\n",
      "Unknown Layer Type               [  1  20   2  40 128]  N/A           N/A          [  1  20   2  40 128]\n",
      "Shape Layer                      [  1  40  40 128]      2             N/A          [  1  40  40 128]\n",
      "Unknown Layer Type               [  1  40  40 128]      N/A           N/A          [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Separable Convolution Layer      [ 1 40 40 24]          38401         61440000     [ 1 40 40 24]\n",
      "Convolution Layer                [   1 9600    4]       2             N/A          [   1 9600    4]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Separable Convolution Layer 1    [ 1 20 20 24]          9601          3840000      [ 1 20 20 24]\n",
      "Convolution Layer                [   1 2400    4]       2             N/A          [   1 2400    4]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Separable Convolution Layer 2    [ 1 10 10 24]          2401          240000       [ 1 10 10 24]\n",
      "Convolution Layer                [  1 600   4]          2             N/A          [  1 600   4]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Separable Convolution Layer 3    [ 1  5  5 24]          601           15000        [ 1  5  5 24]\n",
      "Convolution Layer                [  1 150   4]          2             N/A          [  1 150   4]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [ 1  3  3 24]          217           1944         [ 1  3  3 24]\n",
      "Convolution Layer                [ 1 54  4]             2             N/A          [ 1 54  4]\n",
      "Unknown Layer Type               [    1 12804     4]    N/A           N/A          [    1 12804     4]\n",
      "Depthwise Convolution Layer      [  1  40  40 128]      204801        327680000    [  1  40  40 128]\n",
      "Separable Convolution Layer      [ 1 40 40 30]          48001         76800000     [ 1 40 40 30]\n",
      "Convolution Layer                [   1 9600    5]       2             N/A          [   1 9600    5]\n",
      "Depthwise Convolution Layer      [  1  20  20 128]      51201         20480000     [  1  20  20 128]\n",
      "Separable Convolution Layer 1    [ 1 20 20 30]          12001         4800000      [ 1 20 20 30]\n",
      "Convolution Layer                [   1 2400    5]       2             N/A          [   1 2400    5]\n",
      "Depthwise Convolution Layer      [  1  10  10 128]      12801         1280000      [  1  10  10 128]\n",
      "Separable Convolution Layer 2    [ 1 10 10 30]          3001          300000       [ 1 10 10 30]\n",
      "Convolution Layer                [  1 600   5]          2             N/A          [  1 600   5]\n",
      "Depthwise Convolution Layer      [  1   5   5 128]      3201          80000        [  1   5   5 128]\n",
      "Separable Convolution Layer 3    [ 1  5  5 30]          751           18750        [ 1  5  5 30]\n",
      "Convolution Layer                [  1 150   5]          2             N/A          [  1 150   5]\n",
      "Depthwise Convolution Layer      [  1   3   3 128]      1153          10368        [  1   3   3 128]\n",
      "Separable Convolution Layer      [ 1  3  3 30]          271           2430         [ 1  3  3 30]\n",
      "Convolution Layer                [ 1 54  5]             2             N/A          [ 1 54  5]\n",
      "Unknown Layer Type               [    1 12804     5]    N/A           N/A          [    1 12804     5]\n",
      "Convolution Layer                [    1 12804     5]    2             N/A          [    1 12804     5]\n",
      "Unknown Layer Type               [ 1 10  4]             N/A           N/A          [ 1 10  4]\n",
      "Unknown Layer Type               [ 1 10]                N/A           N/A          [ 1 10]\n",
      "Unknown Layer Type               [ 1 10]                N/A           N/A          [ 1 10]\n",
      "Unknown Layer Type               [1]                    N/A           N/A          [1]\n",
      "Unknown Layer Type               [12804     4]          N/A           N/A          [12804     4]\n",
      "Unknown Layer Type               [12804     5]          N/A           N/A          [12804     5]\n",
      "Unknown Layer Type               [27 32]                N/A           N/A          [27 32]\n",
      "Unknown Layer Type               [32 16]                N/A           N/A          [32 16]\n",
      "Unknown Layer Type               [16 96]                N/A           N/A          [16 96]\n",
      "Unknown Layer Type               [96 24]                N/A           N/A          [96 24]\n",
      "Unknown Layer Type               [ 24 144]              N/A           N/A          [ 24 144]\n",
      "Unknown Layer Type               [144  24]              N/A           N/A          [144  24]\n",
      "Unknown Layer Type               [ 24 144]              N/A           N/A          [ 24 144]\n",
      "Unknown Layer Type               [144  32]              N/A           N/A          [144  32]\n",
      "Unknown Layer Type               [ 32 192]              N/A           N/A          [ 32 192]\n",
      "Unknown Layer Type               [192  32]              N/A           N/A          [192  32]\n",
      "Unknown Layer Type               [ 32 192]              N/A           N/A          [ 32 192]\n",
      "Unknown Layer Type               [192  32]              N/A           N/A          [192  32]\n",
      "Unknown Layer Type               [ 32 128]              N/A           N/A          [ 32 128]\n",
      "Unknown Layer Type               [ 32 192]              N/A           N/A          [ 32 192]\n",
      "Unknown Layer Type               [192  64]              N/A           N/A          [192  64]\n",
      "Unknown Layer Type               [ 64 384]              N/A           N/A          [ 64 384]\n",
      "Unknown Layer Type               [384  64]              N/A           N/A          [384  64]\n",
      "Unknown Layer Type               [ 64 384]              N/A           N/A          [ 64 384]\n",
      "Unknown Layer Type               [384  64]              N/A           N/A          [384  64]\n",
      "Unknown Layer Type               [ 64 384]              N/A           N/A          [ 64 384]\n",
      "Unknown Layer Type               [384  64]              N/A           N/A          [384  64]\n",
      "Unknown Layer Type               [ 64 384]              N/A           N/A          [ 64 384]\n",
      "Unknown Layer Type               [384  96]              N/A           N/A          [384  96]\n",
      "Unknown Layer Type               [ 96 576]              N/A           N/A          [ 96 576]\n",
      "Unknown Layer Type               [576  96]              N/A           N/A          [576  96]\n",
      "Unknown Layer Type               [ 96 576]              N/A           N/A          [ 96 576]\n",
      "Unknown Layer Type               [576  96]              N/A           N/A          [576  96]\n",
      "Unknown Layer Type               [ 96 128]              N/A           N/A          [ 96 128]\n",
      "Unknown Layer Type               [ 96 576]              N/A           N/A          [ 96 576]\n",
      "Unknown Layer Type               [576 160]              N/A           N/A          [576 160]\n",
      "Unknown Layer Type               [160 960]              N/A           N/A          [160 960]\n",
      "Unknown Layer Type               [960 160]              N/A           N/A          [960 160]\n",
      "Unknown Layer Type               [160 960]              N/A           N/A          [160 960]\n",
      "Unknown Layer Type               [960 160]              N/A           N/A          [960 160]\n",
      "Unknown Layer Type               [160 960]              N/A           N/A          [160 960]\n",
      "Unknown Layer Type               [960 320]              N/A           N/A          [960 320]\n",
      "Unknown Layer Type               [ 320 1280]            N/A           N/A          [ 320 1280]\n",
      "Unknown Layer Type               [1280  128]            N/A           N/A          [1280  128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128 128]              N/A           N/A          [128 128]\n",
      "Unknown Layer Type               [128  24]              N/A           N/A          [128  24]\n",
      "Unknown Layer Type               [128  24]              N/A           N/A          [128  24]\n",
      "Unknown Layer Type               [128  24]              N/A           N/A          [128  24]\n",
      "Unknown Layer Type               [128  24]              N/A           N/A          [128  24]\n",
      "Unknown Layer Type               [128  24]              N/A           N/A          [128  24]\n",
      "Unknown Layer Type               [128  30]              N/A           N/A          [128  30]\n",
      "Unknown Layer Type               [128  30]              N/A           N/A          [128  30]\n",
      "Unknown Layer Type               [128  30]              N/A           N/A          [128  30]\n",
      "Unknown Layer Type               [128  30]              N/A           N/A          [128  30]\n",
      "Unknown Layer Type               [128  30]              N/A           N/A          [128  30]\n",
      "Total Parameters: 16749133\n",
      "Total FLOPs: 140108809388\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from decimal import Decimal\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Get input and output details\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "# Initialize table data\n",
    "table_data = []\n",
    "\n",
    "# Get details of all layers\n",
    "total_params = Decimal(0)  # Use Decimal for total_params to handle larger values\n",
    "total_flops = Decimal(0)  # Use Decimal for total_flops to handle larger values\n",
    "\n",
    "for i, layer in enumerate(interpreter.get_tensor_details()):\n",
    "    layer_name = layer['name']\n",
    "    layer_output_shape = layer['shape']\n",
    "\n",
    "    if len(layer_output_shape) > 0:  # Check if the layer has output shape\n",
    "        layer_type = None\n",
    "        \n",
    "        # Check for specific keywords in the layer name to determine the type\n",
    "        if 'conv' in layer_name.lower():\n",
    "            if 'depthwise' in layer_name.lower():\n",
    "                layer_type = 'Depthwise Convolution Layer'\n",
    "            elif 'separable_conv2d' in layer_name.lower():\n",
    "                if 'separable_conv2d_1' in layer_name.lower():\n",
    "                    layer_type = 'Separable Convolution Layer 1'\n",
    "                elif 'separable_conv2d_2' in layer_name.lower():\n",
    "                    layer_type = 'Separable Convolution Layer 2'\n",
    "                elif 'separable_conv2d_3' in layer_name.lower():\n",
    "                    layer_type = 'Separable Convolution Layer 3'\n",
    "                else:\n",
    "                    layer_type = 'Separable Convolution Layer'\n",
    "            else:\n",
    "                layer_type = 'Convolution Layer'\n",
    "        elif 'dense' in layer_name.lower() or 'fullyconnected' in layer_name.lower():\n",
    "            layer_type = 'Fully Connected Layer'\n",
    "        elif 'fusedbatchnormv3' in layer_name.lower():\n",
    "            layer_type = 'Fused Batch Normalization Layer'\n",
    "        elif 'readvariableop' in layer_name.lower():\n",
    "            layer_type = 'Read Variable Operation'\n",
    "        elif 'readvariableop1' in layer_name.lower():\n",
    "            layer_type = 'Read Variable Operation 1'\n",
    "        elif 'shape' in layer_name.lower():\n",
    "            layer_type = 'Shape Layer'\n",
    "        # Add more conditions for other types of layers as needed\n",
    "\n",
    "        if layer_type:\n",
    "            # Count parameters and FLOPs for convolutional layers\n",
    "            if 'conv2d' in layer_name.lower() or 'depthwiseconv2d' in layer_name.lower() or 'separableconv2d' in layer_name.lower():\n",
    "                if len(layer_output_shape) >= 4:  # Check if the shape has enough dimensions\n",
    "                    filter_shape = layer_output_shape[1:3]\n",
    "                    in_channels = layer_output_shape[3]\n",
    "                    out_channels = layer_output_shape[0]\n",
    "                    kernel_size = int(filter_shape[0]) * int(filter_shape[1])\n",
    "\n",
    "                    # Convert numpy integers to regular integers before conversion to Decimal\n",
    "                    params = Decimal(int(kernel_size * in_channels) * int(out_channels) + int(out_channels))  # Weight + bias\n",
    "                    flops = Decimal(int(kernel_size * in_channels) * int(out_channels) * int(layer_output_shape[1]) * int(layer_output_shape[2]))  # MACs\n",
    "\n",
    "                    total_params += params\n",
    "                    total_flops += flops\n",
    "                    \n",
    "                    table_data.append([layer_type, layer_output_shape, params, flops, layer['shape']])\n",
    "                else:\n",
    "                    table_data.append([layer_type, layer_output_shape, \"N/A\", \"N/A\", layer['shape']])\n",
    "            else:\n",
    "                # Assuming other layers (e.g., fully connected) have only bias parameters\n",
    "                params = Decimal(int(layer_output_shape[0]) + 1)  # Bias only\n",
    "                flops = \"N/A\"  # FLOPs calculation not possible without more info\n",
    "\n",
    "                total_params += params\n",
    "\n",
    "                table_data.append([layer_type, layer_output_shape, params, flops, layer['shape']])\n",
    "        else:\n",
    "            table_data.append([\"Unknown Layer Type\", layer_output_shape, \"N/A\", \"N/A\", layer['shape']])\n",
    "    else:\n",
    "        table_data.append([\"Unknown Layer Type\", layer_name, \"N/A\", \"N/A\", \"N/A\"])\n",
    "\n",
    "# Print the table without warnings\n",
    "headers = [\"Layer Type\", \"Output Shape\", \"Parameters\", \"FLOPs\", \"Layer Shape\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"plain\"))\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Total FLOPs: {total_flops}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer Type                         Total Parameters       Total FLOPs\n",
      "Convolution Layer                       3.30622e+06       1.08417e+10\n",
      "Shape Layer                            28                 0\n",
      "Depthwise Convolution Layer             1.26687e+07       1.27153e+11\n",
      "Fused Batch Normalization Layer     14558                 0\n",
      "Separable Convolution Layer        533154                 2.10446e+09\n",
      "Separable Convolution Layer 1       87650                 8.70554e+06\n",
      "Separable Convolution Layer 2       71450            605536\n",
      "Separable Convolution Layer 3       67400             99286\n",
      "Overall Total                           1.67491e+07       1.40109e+11\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from decimal import Decimal\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the TFLite model\n",
    "interpreter = tf.lite.Interpreter(model_path=\"C:/Users/AI/Desktop/Tensorflow/custom_model_lite/detect.tflite\")\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# Initialize dictionaries to store layer-wise parameters and FLOPs\n",
    "layer_params = {}\n",
    "layer_flops = {}\n",
    "\n",
    "# Get details of all layers\n",
    "for i, layer in enumerate(interpreter.get_tensor_details()):\n",
    "    layer_name = layer['name']\n",
    "    layer_output_shape = layer['shape']\n",
    "\n",
    "    if len(layer_output_shape) > 0:  # Check if the layer has output shape\n",
    "        layer_type = None\n",
    "        \n",
    "        # Check for specific keywords in the layer name to determine the type\n",
    "        if 'conv' in layer_name.lower():\n",
    "            if 'depthwise' in layer_name.lower():\n",
    "                layer_type = 'Depthwise Convolution Layer'\n",
    "            elif 'separable_conv2d' in layer_name.lower():\n",
    "                if 'separable_conv2d_1' in layer_name.lower():\n",
    "                    layer_type = 'Separable Convolution Layer 1'\n",
    "                elif 'separable_conv2d_2' in layer_name.lower():\n",
    "                    layer_type = 'Separable Convolution Layer 2'\n",
    "                elif 'separable_conv2d_3' in layer_name.lower():\n",
    "                    layer_type = 'Separable Convolution Layer 3'\n",
    "                else:\n",
    "                    layer_type = 'Separable Convolution Layer'\n",
    "            else:\n",
    "                layer_type = 'Convolution Layer'\n",
    "        elif 'dense' in layer_name.lower() or 'fullyconnected' in layer_name.lower():\n",
    "            layer_type = 'Fully Connected Layer'\n",
    "        elif 'fusedbatchnormv3' in layer_name.lower():\n",
    "            layer_type = 'Fused Batch Normalization Layer'\n",
    "        elif 'readvariableop' in layer_name.lower():\n",
    "            layer_type = 'Read Variable Operation'\n",
    "        elif 'readvariableop1' in layer_name.lower():\n",
    "            layer_type = 'Read Variable Operation 1'\n",
    "        elif 'shape' in layer_name.lower():\n",
    "            layer_type = 'Shape Layer'\n",
    "        # Add more conditions for other types of layers as needed\n",
    "\n",
    "        if layer_type:\n",
    "            # Initialize layer-wise parameters and FLOPs\n",
    "            if layer_type not in layer_params:\n",
    "                layer_params[layer_type] = Decimal(0)\n",
    "                layer_flops[layer_type] = Decimal(0)\n",
    "\n",
    "            # Count parameters and FLOPs for convolutional layers\n",
    "            if 'conv2d' in layer_name.lower() or 'depthwiseconv2d' in layer_name.lower() or 'separableconv2d' in layer_name.lower():\n",
    "                if len(layer_output_shape) >= 4:  # Check if the shape has enough dimensions\n",
    "                    filter_shape = layer_output_shape[1:3]\n",
    "                    in_channels = layer_output_shape[3]\n",
    "                    out_channels = layer_output_shape[0]\n",
    "                    kernel_size = int(filter_shape[0]) * int(filter_shape[1])\n",
    "\n",
    "                    # Convert numpy integers to regular integers before conversion to Decimal\n",
    "                    params = Decimal(int(kernel_size * in_channels) * int(out_channels) + int(out_channels))  # Weight + bias\n",
    "                    flops = Decimal(int(kernel_size * in_channels) * int(out_channels) * int(layer_output_shape[1]) * int(layer_output_shape[2]))  # MACs\n",
    "\n",
    "                    layer_params[layer_type] += params\n",
    "                    layer_flops[layer_type] += flops\n",
    "                else:\n",
    "                    layer_params[layer_type] += Decimal(0)\n",
    "                    layer_flops[layer_type] += Decimal(0)\n",
    "            else:\n",
    "                # Assuming other layers (e.g., fully connected) have only bias parameters\n",
    "                params = Decimal(int(layer_output_shape[0]) + 1)  # Bias only\n",
    "                flops = Decimal(0)  # FLOPs calculation not relevant for non-convolutional layers\n",
    "\n",
    "                layer_params[layer_type] += params\n",
    "\n",
    "# Generate the final table for each layer type\n",
    "table_data = []\n",
    "for layer_type, params in layer_params.items():\n",
    "    flops = layer_flops.get(layer_type, Decimal(0))\n",
    "    table_data.append([layer_type, params, flops])\n",
    "\n",
    "# Calculate overall totals\n",
    "overall_params = sum(layer_params.values())\n",
    "overall_flops = sum(layer_flops.values())\n",
    "\n",
    "# Add the overall totals to the table\n",
    "table_data.append([\"Overall Total\", overall_params, overall_flops])\n",
    "\n",
    "# Print the final table\n",
    "headers = [\"Layer Type\", \"Total Parameters\", \"Total FLOPs\"]\n",
    "print(tabulate(table_data, headers=headers, tablefmt=\"plain\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FLOPS: 0.0338 GFLOPS\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from keras_flops import get_flops\n",
    "\n",
    "def build_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inp = Input(input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inp)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    return model\n",
    "\n",
    "def calculate_flops(model, batch_size=1):\n",
    "    flops = get_flops(model, batch_size=batch_size)\n",
    "    return flops / 10 ** 9  # Convert to GFLOPS\n",
    "\n",
    "# Usage example:\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "flops = calculate_flops(model, batch_size)\n",
    "print(f\"FLOPS: {flops:.03} GFLOPS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1626442\n",
      "Layer: conv2d_56\n",
      "Estimated FLOPs: 16588800.0 FLOPs\n",
      "Parameters: 896\n",
      "\n",
      "Layer: conv2d_57\n",
      "Estimated FLOPs: 57802752.0 FLOPs\n",
      "Parameters: 18496\n",
      "\n",
      "Layer: max_pooling2d_28\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dropout_56\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: flatten_28\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dense_56\n",
      "Estimated FLOPs: 786432 FLOPs\n",
      "Parameters: 1605760\n",
      "\n",
      "Layer: dropout_57\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dense_57\n",
      "Estimated FLOPs: 61440 FLOPs\n",
      "Parameters: 1290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "def build_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inp = Input(input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inp)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    return model\n",
    "\n",
    "def calculate_parameters(model):\n",
    "    total_params = model.count_params()\n",
    "    return total_params\n",
    "\n",
    "def estimate_flops(layer, input_shape=(32, 32, 3)):\n",
    "    input_size = input_shape[0] * input_shape[1] * input_shape[2]\n",
    "    flops = 0  # Initialize flops with a default value\n",
    "    if isinstance(layer, Conv2D):\n",
    "        output_size = layer.output_shape[1] * layer.output_shape[2] * layer.output_shape[3]\n",
    "        flops = (2 * output_size * layer.kernel_size[0] * layer.kernel_size[1] * layer.filters) / layer.strides[0]\n",
    "    elif isinstance(layer, Dense):\n",
    "        output_size = layer.units\n",
    "        flops = (2 * input_size * output_size)  # FLOPs for Dense layers\n",
    "    return flops\n",
    "\n",
    "# Usage example:\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = calculate_parameters(model)\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "# Estimate FLOPs for each layer\n",
    "layer_names = [layer.name for layer in model.layers[1:]]  # Exclude the input layer\n",
    "for idx, layer in enumerate(model.layers[1:]):  # Exclude the input layer\n",
    "    layer_flops = estimate_flops(layer, input_shape)\n",
    "    layer_params = layer.count_params()\n",
    "    print(f\"Layer: {layer_names[idx]}\")\n",
    "    print(f\"Estimated FLOPs: {layer_flops} FLOPs\")  # Removed precision specifier\n",
    "    print(f\"Parameters: {layer_params}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 1626442\n",
      "Total FLOPs: 75239424.0 FLOPs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "def build_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inp = Input(input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inp)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    return model\n",
    "\n",
    "def calculate_total_parameters(model):\n",
    "    return model.count_params()\n",
    "\n",
    "def estimate_total_flops(model, input_shape=(32, 32, 3)):\n",
    "    total_flops = 0\n",
    "    for layer in model.layers[1:]:  # Exclude the input layer\n",
    "        total_flops += estimate_flops(layer, input_shape)\n",
    "    return total_flops\n",
    "\n",
    "def estimate_flops(layer, input_shape=(32, 32, 3)):\n",
    "    input_size = input_shape[0] * input_shape[1] * input_shape[2]\n",
    "    flops = 0  # Initialize flops with a default value\n",
    "    if isinstance(layer, Conv2D):\n",
    "        output_size = layer.output_shape[1] * layer.output_shape[2] * layer.output_shape[3]\n",
    "        flops = (2 * output_size * layer.kernel_size[0] * layer.kernel_size[1] * layer.filters) / layer.strides[0]\n",
    "    elif isinstance(layer, Dense):\n",
    "        output_size = layer.units\n",
    "        flops = (2 * input_size * output_size)  # FLOPs for Dense layers\n",
    "    return flops\n",
    "\n",
    "# Usage example:\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = calculate_total_parameters(model)\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "\n",
    "# Calculate total FLOPs\n",
    "total_flops = estimate_total_flops(model, input_shape)\n",
    "print(f\"Total FLOPs: {total_flops} FLOPs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv2d_68\n",
      "Estimated FLOPs: 16588800.0 FLOPs\n",
      "Parameters: 896\n",
      "\n",
      "Layer: conv2d_69\n",
      "Estimated FLOPs: 57802752.0 FLOPs\n",
      "Parameters: 18496\n",
      "\n",
      "Layer: max_pooling2d_34\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dropout_68\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: flatten_34\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dense_68\n",
      "Estimated FLOPs: 786432 FLOPs\n",
      "Parameters: 1605760\n",
      "\n",
      "Layer: dropout_69\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dense_69\n",
      "Estimated FLOPs: 61440 FLOPs\n",
      "Parameters: 1290\n",
      "\n",
      "Total FLOPs: 75239424.0 FLOPs\n",
      "Total Parameters: 1626442\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "def build_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inp = Input(input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inp)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    return model\n",
    "\n",
    "def calculate_parameters(model):\n",
    "    total_params = model.count_params()\n",
    "    return total_params\n",
    "\n",
    "def estimate_flops(layer, input_shape=(32, 32, 3)):\n",
    "    input_size = input_shape[0] * input_shape[1] * input_shape[2]\n",
    "    flops = 0  # Initialize flops with a default value\n",
    "    if isinstance(layer, Conv2D):\n",
    "        output_size = layer.output_shape[1] * layer.output_shape[2] * layer.output_shape[3]\n",
    "        flops = (2 * output_size * layer.kernel_size[0] * layer.kernel_size[1] * layer.filters) / layer.strides[0]\n",
    "    elif isinstance(layer, Dense):\n",
    "        output_size = layer.units\n",
    "        flops = (2 * input_size * output_size)  # FLOPs for Dense layers\n",
    "    return flops\n",
    "\n",
    "# Usage example:\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = calculate_parameters(model)\n",
    "\n",
    "# Estimate FLOPs for each layer\n",
    "total_flops = 0\n",
    "layer_names = [layer.name for layer in model.layers[1:]]  # Exclude the input layer\n",
    "for idx, layer in enumerate(model.layers[1:]):  # Exclude the input layer\n",
    "    layer_flops = estimate_flops(layer, input_shape)\n",
    "    total_flops += layer_flops\n",
    "    layer_params = layer.count_params()\n",
    "    print(f\"Layer: {layer_names[idx]}\")\n",
    "    print(f\"Estimated FLOPs: {layer_flops} FLOPs\")\n",
    "    print(f\"Parameters: {layer_params}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total FLOPs: {total_flops} FLOPs\")\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: conv2d_102\n",
      "Estimated FLOPs: 777600 FLOPs\n",
      "Parameters: 896\n",
      "\n",
      "Layer: conv2d_103\n",
      "Estimated FLOPs: 1555200 FLOPs\n",
      "Parameters: 18496\n",
      "\n",
      "Layer: max_pooling2d_51\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dropout_102\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: flatten_51\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dense_102\n",
      "Estimated FLOPs: 786560 FLOPs\n",
      "Parameters: 1605760\n",
      "\n",
      "Layer: dropout_103\n",
      "Estimated FLOPs: 0 FLOPs\n",
      "Parameters: 0\n",
      "\n",
      "Layer: dense_103\n",
      "Estimated FLOPs: 61450 FLOPs\n",
      "Parameters: 1290\n",
      "\n",
      "Total FLOPs: 3180810 FLOPs\n",
      "Total Parameters: 1626442\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "\n",
    "def build_model(input_shape=(32, 32, 3), num_classes=10):\n",
    "    inp = Input(input_shape)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inp)\n",
    "    x = Conv2D(64, (3, 3), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    model = Model(inp, out)\n",
    "    return model\n",
    "\n",
    "def calculate_parameters(model):\n",
    "    total_params = model.count_params()\n",
    "    return total_params\n",
    "\n",
    "def estimate_flops(layer, input_shape=(32, 32, 3)):\n",
    "    input_size = input_shape[0] * input_shape[1] * input_shape[2]\n",
    "    flops = 0  # Initialize flops with a default value\n",
    "    if isinstance(layer, Conv2D):\n",
    "        # Ensure padding values are integers\n",
    "        padding_0 = int(layer.padding[0]) if isinstance(layer.padding[0], int) else 0\n",
    "        padding_1 = int(layer.padding[1]) if isinstance(layer.padding[1], int) else 0\n",
    "        # Calculate output size based on input shape and Conv2D parameters\n",
    "        output_height = ((input_shape[0] - layer.kernel_size[0] + 2 * padding_0) // layer.strides[0]) + 1\n",
    "        output_width = ((input_shape[1] - layer.kernel_size[1] + 2 * padding_1) // layer.strides[1]) + 1\n",
    "        output_channels = layer.filters\n",
    "        # Calculate FLOPs for Conv2D layer\n",
    "        flops = output_height * output_width * layer.kernel_size[0] * layer.kernel_size[1] * input_shape[2] * output_channels\n",
    "    elif isinstance(layer, Dense):\n",
    "        output_size = layer.units\n",
    "        # Calculate FLOPs for Dense layer\n",
    "        flops = 2 * input_size * output_size + output_size  # Include FLOPs for biases\n",
    "    return flops\n",
    "\n",
    "# Usage example:\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "batch_size = 1\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "\n",
    "# Calculate total parameters\n",
    "total_params = calculate_parameters(model)\n",
    "\n",
    "# Estimate FLOPs for each layer\n",
    "total_flops = 0\n",
    "layer_names = [layer.name for layer in model.layers[1:]]  # Exclude the input layer\n",
    "for idx, layer in enumerate(model.layers[1:]):  # Exclude the input layer\n",
    "    layer_flops = estimate_flops(layer, input_shape)\n",
    "    total_flops += layer_flops\n",
    "    layer_params = layer.count_params()\n",
    "    print(f\"Layer: {layer_names[idx]}\")\n",
    "    print(f\"Estimated FLOPs: {layer_flops} FLOPs\")\n",
    "    print(f\"Parameters: {layer_params}\")\n",
    "    print()\n",
    "\n",
    "print(f\"Total FLOPs: {total_flops} FLOPs\")\n",
    "print(f\"Total Parameters: {total_params}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face-algo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
